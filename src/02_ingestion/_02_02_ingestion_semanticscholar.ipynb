{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6a80071-2611-4a78-8d60-e4aed2bdccf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utils.py loaded: v0.2.12\n",
      "utils.py loaded: v0.2.12\n",
      "config.py loaded: v0.1\n",
      "config.py loaded: v0.1\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import importlib\n",
    "import subprocess\n",
    "from IPython.display import display\n",
    "# 3\n",
    "# Adding ../01_modules or ./01_modules to the system path so that we can load modules from \n",
    "# there as well\n",
    "modules_path_in_notebook = os.path.abspath(os.path.join(os.getcwd(), '..', '01_modules'))\n",
    "modules_path_in_processing_script = os.path.abspath(os.path.join(os.getcwd(), '01_modules'))\n",
    "if os.path.exists(modules_path_in_notebook):\n",
    "    sys.path.append(modules_path_in_notebook)\n",
    "if os.path.exists(modules_path_in_processing_script):\n",
    "    sys.path.append(modules_path_in_processing_script)\n",
    "\n",
    "result = subprocess.run([\"pwd\"], capture_output=True, text=True)\n",
    "print(result.stdout)\n",
    "result = subprocess.run([\"ls\", \"-l\"], capture_output=True, text=True)\n",
    "print(result.stdout)\n",
    "# # Jupyter only reads a local module the first time after \n",
    "# # kernel start. Re-running a cell with \n",
    "# # \"from mymodulename import *\" would not change\n",
    "# # anything, even if the imported module has since changed.\n",
    "# # As a workaround, we need to directly load the module, \n",
    "# # use importlib.reload to reload it and then import * \n",
    "import utils\n",
    "_ = importlib.reload(utils)\n",
    "import config\n",
    "_ = importlib.reload(config) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7fc7a4c-828a-4f93-9708-a31fe588105f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys stored in Secrets Managers for the secret \"semanticscholar_api_key\": ['x-api-key']\n"
     ]
    }
   ],
   "source": [
    "semanticscholar_secret = utils.get_secret(config.AWS_REGION, config.SEMANTICSCHOLAR_SECRET_NAME)\n",
    "SEMANTICSCHOLAR_API_KEY = semanticscholar_secret[config.SEMANTICSCHOLAR_SECRET_KEY]\n",
    "print(f'Keys stored in Secrets Managers for the secret \"{config.SEMANTICSCHOLAR_SECRET_NAME}\":', list(semanticscholar_secret.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3d80230-8bc3-4b30-81c3-a260ede53193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2022-05-10', '2022-05-17', '2022-05-24', '2022-05-31', '2022-06-07', '2022-06-14', '2022-06-21', '2022-06-28', '2022-07-05', '2022-07-19', '2022-07-28', '2022-08-02', '2022-08-09', '2022-08-16', '2022-08-23', '2022-08-30', '2022-09-06', '2022-09-13', '2022-09-28', '2022-10-05', '2022-10-28', '2022-11-02', '2022-11-11', '2022-11-15', '2022-11-22', '2022-12-02', '2022-12-06', '2022-12-13', '2022-12-20', '2022-12-27', '2023-01-03', '2023-01-10', '2023-01-17', '2023-01-24', '2023-01-31', '2023-02-07', '2023-02-14', '2023-02-21', '2023-02-28', '2023-03-07', '2023-03-14', '2023-03-21', '2023-03-28', '2023-04-06', '2023-04-11', '2023-04-18', '2023-05-09', '2023-05-16', '2023-05-23', '2023-05-30', '2023-06-06', '2023-06-13', '2023-06-20', '2023-07-04', '2023-07-11', '2023-07-25', '2023-08-01', '2023-08-08', '2023-08-15', '2023-08-29', '2023-09-05', '2023-09-12', '2023-09-19', '2023-09-26', '2023-10-10', '2023-10-19', '2023-10-24', '2023-10-31', '2023-11-07', '2023-11-14', '2023-11-21', '2023-11-28', '2023-12-05', '2023-12-12', '2023-12-27', '2024-01-02', '2024-01-24', '2024-01-30', '2024-02-06', '2024-02-20', '2024-02-27', '2024-03-05', '2024-03-12', '2024-03-19', '2024-03-26', '2024-04-02', '2024-04-09', '2024-04-16', '2024-04-23', '2024-04-30', '2024-05-07', '2024-05-14', '2024-05-21', '2024-05-28', '2024-06-04', '2024-06-11', '2024-06-18', '2024-06-25', '2024-07-02', '2024-07-09', '2024-07-16', '2024-07-23', '2024-07-30', '2024-08-06', '2024-08-13', '2024-08-20', '2024-08-27', '2024-09-03', '2024-09-17', '2024-09-24', '2024-10-01', '2024-10-08', '2024-10-15', '2024-10-22', '2024-10-29', '2024-11-05', '2024-11-12', '2024-11-19', '2024-11-26', '2024-12-03', '2024-12-10', '2024-12-17', '2024-12-24', '2024-12-31', '2025-01-07', '2025-01-14', '2025-01-21', '2025-01-28', '2025-02-04', '2025-02-11', '2025-02-18', '2025-02-25', '2025-03-04', '2025-03-11', '2025-03-18', '2025-03-25', '2025-04-01', '2025-04-08', '2025-04-15', '2025-04-22', '2025-05-06', '2025-05-13', '2025-05-20', '2025-05-27', '2025-06-03', '2025-06-10', '2025-06-17', '2025-07-03', '2025-07-08', '2025-07-15', '2025-07-22', '2025-07-29', '2025-08-05', '2025-08-12']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'papers',\n",
       " 'description': 'The core attributes of a paper (title, authors, date, etc.).\\n200M records in 30 1.5GB files.',\n",
       " 'README': 'Semantic Scholar Academic Graph Datasets\\n\\nThe \"papers\" dataset provides core metadata about papers.\\n\\nSCHEMA\\nSee https://api.semanticscholar.org/api-docs/graph#tag/Paper-Data\\n\\nThis dataset does not contain information about a paper\\'s references or citations.\\nInstead, join with citingPaperId/citedPaperId from the \"citations\" dataset.\\n\\nLICENSE\\nThis collection is licensed under ODC-BY. (https://opendatacommons.org/licenses/by/1.0/)\\n\\nBy downloading this data you acknowledge that you have read and agreed to all the terms in this license.\\n\\nATTRIBUTION\\nWhen using this data in a product or service, or including data in a redistribution, please cite the following paper:\\n\\nBibTex format:\\n@misc{https://doi.org/10.48550/arxiv.2301.10140,\\n  title = {The Semantic Scholar Open Data Platform},\\n  author = {Kinney, Rodney and Anastasiades, Chloe and Authur, Russell and Beltagy, Iz and Bragg, Jonathan and Buraczynski, Alexandra and Cachola, Isabel and Candra, Stefan and Chandrasekhar, Yoganand and Cohan, Arman and Crawford, Miles and Downey, Doug and Dunkelberger, Jason and Etzioni, Oren and Evans, Rob and Feldman, Sergey and Gorney, Joseph and Graham, David and Hu, Fangzhou and Huff, Regan and King, Daniel and Kohlmeier, Sebastian and Kuehl, Bailey and Langan, Michael and Lin, Daniel and Liu, Haokun and Lo, Kyle and Lochner, Jaron and MacMillan, Kelsey and Murray, Tyler and Newell, Chris and Rao, Smita and Rohatgi, Shaurya and Sayre, Paul and Shen, Zejiang and Singh, Amanpreet and Soldaini, Luca and Subramanian, Shivashankar and Tanaka, Amber and Wade, Alex D. and Wagner, Linda and Wang, Lucy Lu and Wilhelm, Chris and Wu, Caroline and Yang, Jiangjiang and Zamarron, Angele and Van Zuylen, Madeleine and Weld, Daniel S.},\\n  publisher = {arXiv},\\n  year = {2023},\\n  doi = {10.48550/ARXIV.2301.10140},\\n  url = {https://arxiv.org/abs/2301.10140},\\n}\\n\\n\\n'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'name': 's2orc',\n",
       " 'description': 'Full-body paper text parsed from open-access PDFs. Identifies structural elements such as paragraphs, sections, and bibliography entries.\\n10M records in 30 4GB files.',\n",
       " 'README': 'Semantic Scholar Academic Graph Datasets\\n\\nThe \"s2orc\" dataset contains parsed full-body text from selected papers.\\n\\nA subset of this data was previously released (in a different format) as S2ORC https://github.com/allenai/s2orc\\n\\nThe body text is parsed from PDF documents using Grobid, documented at https://grobid.readthedocs.io.\\nIts output is converted from XML into a single string with a set of annotation spans.\\n\\nSCHEMA\\n - externalIds: IDs of this paper in different catalogs\\n - content:\\n   - source:\\n\\t   - pdfUrls: URLs to the PDF\\n\\t   - oaInfo: license/url/status information from Unpaywall\\n   - text: Full body text as a single string\\n   - annotations: Annotated spans of the full body text\\n\\n\\nLICENSE\\nThis collection is licensed under ODC-BY. (https://opendatacommons.org/licenses/by/1.0/)\\n\\nBy downloading this data you acknowledge that you have read and agreed to all the terms in this license.\\n\\nATTRIBUTION\\nWhen using this data in a product or service, or including data in a redistribution, please cite the following paper:\\n\\n@inproceedings{lo-wang-2020-s2orc,\\n    title = \"{S}2{ORC}: The Semantic Scholar Open Research Corpus\",\\n    author = \"Lo, Kyle  and Wang, Lucy Lu  and Neumann, Mark  and Kinney, Rodney  and Weld, Daniel\",\\n    booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/2020.acl-main.447\",\\n    doi = \"10.18653/v1/2020.acl-main.447\",\\n    pages = \"4969--4983\"\\n}\\n'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2025-08-12'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def semanticscholar_get_release_ids():\n",
    "    \"\"\"Fetching the list of dataset release IDs.\"\"\"\n",
    "    response = requests.get(config.SEMANTICSCHOLAR_API_BASE_URL)\n",
    "    response.raise_for_status()\n",
    "    res = response.json()\n",
    "    print(res)\n",
    "    return res\n",
    "\n",
    "\n",
    "def semanticscholar_get_latest_metadata(release_id):\n",
    "    \"\"\"Fetch the metadata for the latest dataset release.\"\"\"\n",
    "    url = f'{config.SEMANTICSCHOLAR_API_BASE_URL}/{release_id}'\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    res_json = response.json()\n",
    "    res = []\n",
    "    for dataset in res_json['datasets']:\n",
    "        if dataset['name'] in ['papers', 's2orc']:\n",
    "            res.append(dataset)\n",
    "            display(dataset)\n",
    "    return res\n",
    "\n",
    "\n",
    "def get_releases_and_metadata():\n",
    "    release_ids = semanticscholar_get_release_ids()\n",
    "    latest_release_id = release_ids[-1]\n",
    "\n",
    "    semanticscholar_get_latest_metadata(latest_release_id)\n",
    "    return latest_release_id\n",
    "\n",
    "\n",
    "SEMANTICSCHOLAR_LATEST_RELEASE_ID = get_releases_and_metadata()\n",
    "SEMANTICSCHOLAR_LATEST_RELEASE_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b77cebb-7a4f-495e-beed-039209af2568",
   "metadata": {
    "lines_to_next_cell": 3
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(runtype='dev', test_argument_key_01='test-argument-default-value-01', test_argument_key_02='test-argument-default-value-02')\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--runtype\", type=str, default='dev')\n",
    "parser.add_argument(\"--test-argument-key-01\", type=str, default='test-argument-default-value-01')\n",
    "parser.add_argument(\"--test-argument-key-02\", type=str, default='test-argument-default-value-02')\n",
    "args, _ = parser.parse_known_args()\n",
    "RUNTYPE = args.runtype\n",
    "\n",
    "print (args)\n",
    "\n",
    "if RUNTYPE == 'dev':\n",
    "    PROCESSING_FILEPATH_PREFIX = '_dev_processing'\n",
    "elif RUNTYPE == 'prod':\n",
    "    PROCESSING_FILEPATH_PREFIX = config.DEFAULT_PROCESSING_FILEPATH_PREFIX\n",
    "else:\n",
    "    raise ValueError('Argument --runtype should be either \"dev\" or \"prod\" (without quotes).')\n",
    "\n",
    "PROCESSING_FILEPATH_INPUT = f'{PROCESSING_FILEPATH_PREFIX}/input/data/'\n",
    "PROCESSING_FILEPATH_OUTPUT = f'{PROCESSING_FILEPATH_PREFIX}/output/results/'\n",
    "\n",
    "utils.ensure_path(PROCESSING_FILEPATH_INPUT)\n",
    "utils.ensure_path(PROCESSING_FILEPATH_OUTPUT)\n",
    "\n",
    "with open(os.path.join(PROCESSING_FILEPATH_INPUT, 'test.txt'), \"r\", encoding='utf-8') as test_file:\n",
    "    test_content = test_file.read()\n",
    "\n",
    "with open(os.path.join(PROCESSING_FILEPATH_OUTPUT, 'results.txt'), \"w\", encoding='utf-8') as results_file:\n",
    "    results_file.write('\\n'.join([\n",
    "        f'semanticscholar_secret_keys[0]: {list(semanticscholar_secret.keys())[0]}',\n",
    "        f'SEMANTICSCHOLAR_LATEST_RELEASE_ID: {SEMANTICSCHOLAR_LATEST_RELEASE_ID}',\n",
    "        f'test_content: {test_content}',\n",
    "        f'args.test_argument_key_01: {args.test_argument_key_01}',\n",
    "        f'args.test_argument_key_02: {args.test_argument_key_02}'\n",
    "    ]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_311",
   "language": "python",
   "name": "python_311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
