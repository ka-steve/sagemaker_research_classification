{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1344db8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T00:58:04.147909Z",
     "iopub.status.busy": "2025-09-05T00:58:04.147462Z",
     "iopub.status.idle": "2025-09-05T00:58:14.686360Z",
     "shell.execute_reply": "2025-09-05T00:58:14.685411Z",
     "shell.execute_reply.started": "2025-09-05T00:58:04.147885Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "config.py loaded: v0.1\n",
      "utils.py loaded: v0.2.12\n",
      "utils.py loaded: v0.2.12\n",
      "config.py loaded: v0.1\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import importlib\n",
    "import transformers\n",
    "import torch\n",
    "import pathlib\n",
    "import awswrangler as wr\n",
    "from IPython.display import display\n",
    "from sagemaker.huggingface.processing import HuggingFaceProcessor\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import FrameworkProcessor\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.session import get_execution_role\n",
    "\n",
    "\n",
    "# Adding ../01_modules or ./01_modules to the system path so that we can load modules from \n",
    "# there as well\n",
    "if '__file__' in globals():\n",
    "    script_dir = pathlib.Path(__file__).parent.resolve()\n",
    "else:\n",
    "    script_dir = pathlib.Path().absolute()\n",
    "modules_path_in_dev = os.path.abspath(os.path.join(script_dir, '..', '01_modules'))\n",
    "modules_path_in_prod = os.path.abspath(os.path.join(script_dir, '01_modules'))\n",
    "if os.path.exists(modules_path_in_dev):\n",
    "    sys.path.append(modules_path_in_dev)\n",
    "if os.path.exists(modules_path_in_prod):\n",
    "    sys.path.append(modules_path_in_prod)\n",
    "\n",
    "\n",
    "# # Jupyter only reads a local module the first time after \n",
    "# # kernel start. Re-running a cell with \n",
    "# # \"from mymodulename import *\" would not change\n",
    "# # anything, even if the imported module has since changed.\n",
    "# # As a workaround, we need to directly load the module, \n",
    "# # use importlib.reload to reload it and then import * \n",
    "import utils\n",
    "_ = importlib.reload(utils)\n",
    "import config\n",
    "_ = importlib.reload(config) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4d49f5f-2a5e-46e7-8e23-d17e557c8f26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T00:58:14.687338Z",
     "iopub.status.busy": "2025-09-05T00:58:14.687129Z",
     "iopub.status.idle": "2025-09-05T00:58:20.420868Z",
     "shell.execute_reply": "2025-09-05T00:58:20.419997Z",
     "shell.execute_reply.started": "2025-09-05T00:58:14.687321Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: reorganize\n",
    "\n",
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoConfig, \n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer)\n",
    "\n",
    "from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig\n",
    "import evaluate\n",
    "#import torch\n",
    "import lighteval\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "500af03e-de91-497c-b18b-834b312066c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T00:59:03.827324Z",
     "iopub.status.busy": "2025-09-05T00:59:03.826985Z",
     "iopub.status.idle": "2025-09-05T00:59:03.830864Z",
     "shell.execute_reply": "2025-09-05T00:59:03.830126Z",
     "shell.execute_reply.started": "2025-09-05T00:59:03.827295Z"
    }
   },
   "outputs": [],
   "source": [
    "# PRETRAINED_MODEL_NAME = 'roberta-base'\n",
    "# LABEL_TYPE = 'topic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65a91678-fb9b-467f-a96d-d7ba27248183",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T00:59:04.849794Z",
     "iopub.status.busy": "2025-09-05T00:59:04.849389Z",
     "iopub.status.idle": "2025-09-05T00:59:04.855989Z",
     "shell.execute_reply": "2025-09-05T00:59:04.855077Z",
     "shell.execute_reply.started": "2025-09-05T00:59:04.849762Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b0a7858-79ae-49e9-8dd5-2338ab4fd2fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T00:59:05.696162Z",
     "iopub.status.busy": "2025-09-05T00:59:05.695796Z",
     "iopub.status.idle": "2025-09-05T00:59:05.714377Z",
     "shell.execute_reply": "2025-09-05T00:59:05.713365Z",
     "shell.execute_reply.started": "2025-09-05T00:59:05.696132Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(model_name='distilbert-base-uncased', hf_dataset_suffix='_Title_SubfieldIndex', label_type='subfield', text_key='title', text_key_rename_to='text', label_key_rename_to='label', epochs=3, train_batch_size=32, eval_batch_size=64, warmup_steps=500, learning_rate=5e-05, output_data_dir='SM_OUTPUT_DATA_DIR', model_dir='SM_MODEL_DIR', n_gpus=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument(\"--model_name\", type=str, default='distilbert-base-uncased')\n",
    "parser.add_argument(\"--hf_dataset_suffix\", type=str, default='_Title_SubfieldIndex')\n",
    "parser.add_argument(\"--label_type\", type=str, default='subfield')\n",
    "parser.add_argument(\"--text_key\", type=str, default='title')\n",
    "parser.add_argument(\"--text_key_rename_to\", type=str, default='text')\n",
    "parser.add_argument(\"--label_key_rename_to\", type=str, default='label')\n",
    "\n",
    "parser.add_argument(\"--epochs\", type=int, default=3)\n",
    "parser.add_argument(\"--train_batch_size\", type=int, default=32)\n",
    "parser.add_argument(\"--eval_batch_size\", type=int, default=64)\n",
    "parser.add_argument(\"--warmup_steps\", type=int, default=500)\n",
    "parser.add_argument(\"--learning_rate\", type=str, default=5e-5)\n",
    "\n",
    "# Data, model, and output directories\n",
    "parser.add_argument(\"--output_data_dir\", type=str, default='SM_OUTPUT_DATA_DIR') # os.environ['SM_OUTPUT_DATA_DIR'])\n",
    "parser.add_argument(\"--model_dir\", type=str, default='SM_MODEL_DIR') # os.environ['SM_MODEL_DIR'])\n",
    "parser.add_argument(\"--n_gpus\", type=str, default=torch.cuda.device_count()) # os.environ['SM_NUM_GPUS'])\n",
    "\n",
    "args, _ = parser.parse_known_args()\n",
    "LABEL_KEY = f'{args.label_type}_index'\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "954cf37d-c847-4f16-9de4-b61fe0e2dd12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T00:59:08.020825Z",
     "iopub.status.busy": "2025-09-05T00:59:08.020550Z",
     "iopub.status.idle": "2025-09-05T00:59:10.357421Z",
     "shell.execute_reply": "2025-09-05T00:59:10.356795Z",
     "shell.execute_reply.started": "2025-09-05T00:59:08.020804Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 346344\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 43439\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 43478\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset('SteveAKopias/SemanticScholarCSFullTextWithOpenAlexTopics'+args.hf_dataset_suffix)\n",
    "dataset = dataset.rename_column(args.text_key, args.text_key_rename_to)\n",
    "dataset = dataset.rename_column(LABEL_KEY, args.label_key_rename_to)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69d7aed0-122b-4831-ab4c-17c105685aae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T00:59:18.226704Z",
     "iopub.status.busy": "2025-09-05T00:59:18.226431Z",
     "iopub.status.idle": "2025-09-05T00:59:21.723018Z",
     "shell.execute_reply": "2025-09-05T00:59:21.722282Z",
     "shell.execute_reply.started": "2025-09-05T00:59:18.226682Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index2label {0: 'Artificial Intelligence', 3: 'Computer Networks and Communications', 4: 'Computational Theory and Mathematics', 7: 'Computer Science Applications', 8: 'Hardware and Architecture', 9: 'Computer Graphics and Computer-Aided Design', 10: 'Software', 5: 'Signal Processing', 6: 'Human-Computer Interaction', 1: 'Computer Vision and Pattern Recognition', 2: 'Information Systems'}\n",
      "label2index {'Artificial Intelligence': 0, 'Computer Networks and Communications': 3, 'Computational Theory and Mathematics': 4, 'Computer Science Applications': 7, 'Hardware and Architecture': 8, 'Computer Graphics and Computer-Aided Design': 9, 'Software': 10, 'Signal Processing': 5, 'Human-Computer Interaction': 6, 'Computer Vision and Pattern Recognition': 1, 'Information Systems': 2}\n"
     ]
    }
   ],
   "source": [
    "label_df = wr.athena.read_sql_query(\n",
    "f\"\"\"\n",
    "SELECT \n",
    "    {args.label_type}_index AS index, \n",
    "    {args.label_type}_display_name AS display_name\n",
    "FROM\n",
    "    {args.label_type}s\n",
    "\"\"\", '03_core'\n",
    ")\n",
    "index2label = dict(zip(label_df[f'index'].astype(int), label_df['display_name']))\n",
    "label2index = dict(zip(label_df['display_name'], label_df['index'].astype(int)))\n",
    "print('index2label', index2label)\n",
    "print('label2index', label2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a517377-c386-4a1d-9714-56c480763dee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T00:59:27.517041Z",
     "iopub.status.busy": "2025-09-05T00:59:27.516736Z",
     "iopub.status.idle": "2025-09-05T00:59:27.521593Z",
     "shell.execute_reply": "2025-09-05T00:59:27.520895Z",
     "shell.execute_reply.started": "2025-09-05T00:59:27.517020Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da7aecd0-a914-4bfc-ae5d-aed9c407cdd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T00:59:29.144989Z",
     "iopub.status.busy": "2025-09-05T00:59:29.144711Z",
     "iopub.status.idle": "2025-09-05T00:59:29.455013Z",
     "shell.execute_reply": "2025-09-05T00:59:29.454259Z",
     "shell.execute_reply.started": "2025-09-05T00:59:29.144967Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    args.model_name,\n",
    "    num_labels=label_df.shape[0],\n",
    "    id2label=index2label,\n",
    "    label2id=label2index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fab078c-d551-4347-a1d6-ce57d7ab023f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T00:59:30.831649Z",
     "iopub.status.busy": "2025-09-05T00:59:30.831376Z",
     "iopub.status.idle": "2025-09-05T00:59:30.836858Z",
     "shell.execute_reply": "2025-09-05T00:59:30.836071Z",
     "shell.execute_reply.started": "2025-09-05T00:59:30.831629Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=11, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1204a998-c101-4e19-bcf9-e24a5091fdbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T00:59:32.574749Z",
     "iopub.status.busy": "2025-09-05T00:59:32.574490Z",
     "iopub.status.idle": "2025-09-05T00:59:32.735556Z",
     "shell.execute_reply": "2025-09-05T00:59:32.735002Z",
     "shell.execute_reply.started": "2025-09-05T00:59:32.574729Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertTokenizerFast(name_or_path='distilbert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(args.model_name, add_prefix_space=True)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c24e56c-3044-436e-abee-5f436395eb5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T00:59:34.559168Z",
     "iopub.status.busy": "2025-09-05T00:59:34.558804Z",
     "iopub.status.idle": "2025-09-05T00:59:34.562696Z",
     "shell.execute_reply": "2025-09-05T00:59:34.561991Z",
     "shell.execute_reply.started": "2025-09-05T00:59:34.559140Z"
    }
   },
   "outputs": [],
   "source": [
    "# if tokenizer.pad_token is None:\n",
    "#    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "#    model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9a25f56-f66b-4cc2-9e00-5e6a14a9e58f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T00:59:35.073294Z",
     "iopub.status.busy": "2025-09-05T00:59:35.072858Z",
     "iopub.status.idle": "2025-09-05T01:00:25.085588Z",
     "shell.execute_reply": "2025-09-05T01:00:25.084574Z",
     "shell.execute_reply.started": "2025-09-05T00:59:35.073263Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ef62fa341f24fcbbde7ec147bd9b293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/346344 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b95519cc19af4eb68ed6b3dd05810ea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/43439 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f15c21226dd344d09af4be91feb7696e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/43478 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 346344\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 43439\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 43478\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_function(example):\n",
    "    text = example[args.text_key_rename_to]\n",
    "    tokenizer.truncation_side = 'right'\n",
    "    tokenized_inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors='np',\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "    return tokenized_inputs\n",
    "\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6face8c7-a822-4cd7-8377-3183b67e0ffe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T01:00:36.551989Z",
     "iopub.status.busy": "2025-09-05T01:00:36.551589Z",
     "iopub.status.idle": "2025-09-05T01:00:36.564572Z",
     "shell.execute_reply": "2025-09-05T01:00:36.563795Z",
     "shell.execute_reply.started": "2025-09-05T01:00:36.551955Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['ISOMORPHIC SIGNAL ENSEMBLES AND THEIR APPLICATION IN ASYNC-ADDRESS SYSTEMS',\n",
       "  'The Maximal Running Time of Hypergraph Bootstrap Percolation',\n",
       "  'Maximal Length Cellular Automata : A Survey',\n",
       "  \"Towards solid abelian groups: A formal proof of Nöbeling's theorem\",\n",
       "  'The Linear Arboricity of IC-planar Graphs'],\n",
       " 'label': [5, 5, 5, 5, 5],\n",
       " 'input_ids': [[101,\n",
       "   11163,\n",
       "   18078,\n",
       "   4742,\n",
       "   21528,\n",
       "   1998,\n",
       "   2037,\n",
       "   4646,\n",
       "   1999,\n",
       "   2004,\n",
       "   6038,\n",
       "   2278,\n",
       "   1011,\n",
       "   4769,\n",
       "   3001,\n",
       "   102],\n",
       "  [101,\n",
       "   1996,\n",
       "   29160,\n",
       "   2770,\n",
       "   2051,\n",
       "   1997,\n",
       "   23760,\n",
       "   14413,\n",
       "   6879,\n",
       "   6494,\n",
       "   2361,\n",
       "   2566,\n",
       "   26289,\n",
       "   3508,\n",
       "   102],\n",
       "  [101, 29160, 3091, 12562, 8285, 21022, 1024, 1037, 5002, 102],\n",
       "  [101,\n",
       "   2875,\n",
       "   5024,\n",
       "   16768,\n",
       "   2937,\n",
       "   2967,\n",
       "   1024,\n",
       "   1037,\n",
       "   5337,\n",
       "   6947,\n",
       "   1997,\n",
       "   10501,\n",
       "   2075,\n",
       "   1005,\n",
       "   1055,\n",
       "   9872,\n",
       "   102],\n",
       "  [101,\n",
       "   1996,\n",
       "   7399,\n",
       "   19679,\n",
       "   28775,\n",
       "   3723,\n",
       "   1997,\n",
       "   24582,\n",
       "   1011,\n",
       "   2933,\n",
       "   2906,\n",
       "   19287,\n",
       "   102]],\n",
       " 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset['train'][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d83b1943-37b7-449e-8cb5-7a47ca55593e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T01:00:42.597162Z",
     "iopub.status.busy": "2025-09-05T01:00:42.596882Z",
     "iopub.status.idle": "2025-09-05T01:00:42.601546Z",
     "shell.execute_reply": "2025-09-05T01:00:42.600917Z",
     "shell.execute_reply.started": "2025-09-05T01:00:42.597142Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorWithPadding(tokenizer=DistilBertTokenizerFast(name_or_path='distilbert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       "), padding=True, max_length=None, pad_to_multiple_of=None, return_tensors='pt')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec072d23-5c4c-43a4-87cf-990cb49a2391",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T01:00:44.518118Z",
     "iopub.status.busy": "2025-09-05T01:00:44.517748Z",
     "iopub.status.idle": "2025-09-05T01:00:44.523748Z",
     "shell.execute_reply": "2025-09-05T01:00:44.522856Z",
     "shell.execute_reply.started": "2025-09-05T01:00:44.518089Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "# TODO: replace it with lighteval?\n",
    "# accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    predictions = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"binary\")\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': accuracy, \n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e32e30af-9377-4d8c-8111-12669b09f8bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T01:00:47.372135Z",
     "iopub.status.busy": "2025-09-05T01:00:47.371861Z",
     "iopub.status.idle": "2025-09-05T01:00:47.382632Z",
     "shell.execute_reply": "2025-09-05T01:00:47.381923Z",
     "shell.execute_reply.started": "2025-09-05T01:00:47.372115Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArguments(\n",
       "_n_gpu=0,\n",
       "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
       "adafactor=False,\n",
       "adam_beta1=0.9,\n",
       "adam_beta2=0.999,\n",
       "adam_epsilon=1e-08,\n",
       "auto_find_batch_size=False,\n",
       "average_tokens_across_devices=False,\n",
       "batch_eval_metrics=False,\n",
       "bf16=False,\n",
       "bf16_full_eval=False,\n",
       "data_seed=None,\n",
       "dataloader_drop_last=False,\n",
       "dataloader_num_workers=0,\n",
       "dataloader_persistent_workers=False,\n",
       "dataloader_pin_memory=True,\n",
       "dataloader_prefetch_factor=None,\n",
       "ddp_backend=None,\n",
       "ddp_broadcast_buffers=None,\n",
       "ddp_bucket_cap_mb=None,\n",
       "ddp_find_unused_parameters=None,\n",
       "ddp_timeout=1800,\n",
       "debug=[],\n",
       "deepspeed=None,\n",
       "disable_tqdm=False,\n",
       "dispatch_batches=None,\n",
       "do_eval=True,\n",
       "do_predict=False,\n",
       "do_train=False,\n",
       "eval_accumulation_steps=None,\n",
       "eval_delay=0,\n",
       "eval_do_concat_batches=True,\n",
       "eval_on_start=False,\n",
       "eval_steps=None,\n",
       "eval_strategy=IntervalStrategy.EPOCH,\n",
       "eval_use_gather_object=False,\n",
       "evaluation_strategy=None,\n",
       "fp16=False,\n",
       "fp16_backend=auto,\n",
       "fp16_full_eval=False,\n",
       "fp16_opt_level=O1,\n",
       "fsdp=[],\n",
       "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
       "fsdp_min_num_params=0,\n",
       "fsdp_transformer_layer_cls_to_wrap=None,\n",
       "full_determinism=False,\n",
       "gradient_accumulation_steps=1,\n",
       "gradient_checkpointing=False,\n",
       "gradient_checkpointing_kwargs=None,\n",
       "greater_is_better=None,\n",
       "group_by_length=False,\n",
       "half_precision_backend=auto,\n",
       "hub_always_push=False,\n",
       "hub_model_id=None,\n",
       "hub_private_repo=None,\n",
       "hub_strategy=HubStrategy.EVERY_SAVE,\n",
       "hub_token=<HUB_TOKEN>,\n",
       "ignore_data_skip=False,\n",
       "include_for_metrics=[],\n",
       "include_inputs_for_metrics=False,\n",
       "include_num_input_tokens_seen=False,\n",
       "include_tokens_per_second=False,\n",
       "jit_mode_eval=False,\n",
       "label_names=None,\n",
       "label_smoothing_factor=0.0,\n",
       "learning_rate=5e-05,\n",
       "length_column_name=length,\n",
       "load_best_model_at_end=False,\n",
       "local_rank=0,\n",
       "log_level=passive,\n",
       "log_level_replica=warning,\n",
       "log_on_each_node=True,\n",
       "logging_dir=SM_OUTPUT_DATA_DIR/logs,\n",
       "logging_first_step=False,\n",
       "logging_nan_inf_filter=True,\n",
       "logging_steps=500,\n",
       "logging_strategy=IntervalStrategy.STEPS,\n",
       "lr_scheduler_kwargs={},\n",
       "lr_scheduler_type=SchedulerType.LINEAR,\n",
       "max_grad_norm=1.0,\n",
       "max_steps=-1,\n",
       "metric_for_best_model=None,\n",
       "mp_parameters=,\n",
       "neftune_noise_alpha=None,\n",
       "no_cuda=False,\n",
       "num_train_epochs=3,\n",
       "optim=OptimizerNames.ADAMW_TORCH,\n",
       "optim_args=None,\n",
       "optim_target_modules=None,\n",
       "output_dir=SM_MODEL_DIR,\n",
       "overwrite_output_dir=False,\n",
       "past_index=-1,\n",
       "per_device_eval_batch_size=8,\n",
       "per_device_train_batch_size=8,\n",
       "prediction_loss_only=False,\n",
       "push_to_hub=False,\n",
       "push_to_hub_model_id=None,\n",
       "push_to_hub_organization=None,\n",
       "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
       "ray_scope=last,\n",
       "remove_unused_columns=True,\n",
       "report_to=[],\n",
       "restore_callback_states_from_checkpoint=False,\n",
       "resume_from_checkpoint=None,\n",
       "run_name=SM_MODEL_DIR,\n",
       "save_on_each_node=False,\n",
       "save_only_model=False,\n",
       "save_safetensors=True,\n",
       "save_steps=500,\n",
       "save_strategy=SaveStrategy.STEPS,\n",
       "save_total_limit=None,\n",
       "seed=42,\n",
       "skip_memory_metrics=True,\n",
       "split_batches=None,\n",
       "tf32=None,\n",
       "torch_compile=False,\n",
       "torch_compile_backend=None,\n",
       "torch_compile_mode=None,\n",
       "torch_empty_cache_steps=None,\n",
       "torchdynamo=None,\n",
       "tpu_metrics_debug=False,\n",
       "tpu_num_cores=None,\n",
       "use_cpu=False,\n",
       "use_ipex=False,\n",
       "use_legacy_prediction_loop=False,\n",
       "use_liger_kernel=False,\n",
       "use_mps_device=False,\n",
       "warmup_ratio=0.0,\n",
       "warmup_steps=0,\n",
       "weight_decay=0.0,\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=args.model_dir,\n",
    "    num_train_epochs=args.epochs,\n",
    "    # per_device_train_batch_size=args.train_batch_size,\n",
    "    # per_device_eval_batch_size=args.eval_batch_size,\n",
    "    # warmup_steps=args.warmup_steps,\n",
    "    eval_strategy='epoch',\n",
    "    logging_dir=f'{args.output_data_dir}/logs',\n",
    "    learning_rate=float(args.learning_rate),\n",
    ")\n",
    "training_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7147d461-9cfc-432d-99ba-3df2102b3a2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T01:00:52.792478Z",
     "iopub.status.busy": "2025-09-05T01:00:52.792219Z",
     "iopub.status.idle": "2025-09-05T01:00:52.819053Z",
     "shell.execute_reply": "2025-09-05T01:00:52.818397Z",
     "shell.execute_reply.started": "2025-09-05T01:00:52.792458Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['test'],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29949c81-4314-4998-b0e2-3aa632e64046",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T01:00:54.679436Z",
     "iopub.status.busy": "2025-09-05T01:00:54.679085Z",
     "iopub.status.idle": "2025-09-05T01:01:45.485534Z",
     "shell.execute_reply": "2025-09-05T01:01:45.483563Z",
     "shell.execute_reply.started": "2025-09-05T01:00:54.679409Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='129879' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [    23/129879 00:40 < 69:31:11, 0.52 it/s, Epoch 0.00/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000\">╭─────────────────────────────── </span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">Traceback </span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #ff0000; text-decoration-color: #ff0000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> in &lt;module&gt;:1                                                                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 <span style=\"font-weight: bold; text-decoration: underline\">trainer.train()</span>                                                                              <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">/home/sagemaker-user/.conda/envs/python_311/lib/python3.11/site-packages/transformers/</span><span style=\"font-weight: bold\">trainer.py</span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> :2241 in train                                                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2238 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">finally</span>:                                                                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2239 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>hf_hub_utils.enable_progress_bars()                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2240 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2241 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"font-weight: bold; text-decoration: underline\">inner_training_loop(</span>                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2242 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"font-weight: bold; text-decoration: underline\">args=args,</span>                                                                <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2243 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"font-weight: bold; text-decoration: underline\">resume_from_checkpoint=resume_from_checkpoint,</span>                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2244 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"font-weight: bold; text-decoration: underline\">trial=trial,</span>                                                              <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">/home/sagemaker-user/.conda/envs/python_311/lib/python3.11/site-packages/transformers/</span><span style=\"font-weight: bold\">trainer.py</span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> :2548 in _inner_training_loop                                                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2545 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> contextlib.nullcontext                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2546 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>)                                                                     <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2547 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> context():                                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2548 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   </span>tr_loss_step = <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; text-decoration: underline\">self</span><span style=\"font-weight: bold; text-decoration: underline\">.training_step(model, inputs, num_items_in_ba</span>  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2549 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>                                                                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2550 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> (                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2551 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   </span>args.logging_nan_inf_filter                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">/home/sagemaker-user/.conda/envs/python_311/lib/python3.11/site-packages/transformers/</span><span style=\"font-weight: bold\">trainer.py</span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> :3740 in training_step                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3737 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.accelerator.distributed_type == DistributedType.DEEPSPEED:            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3738 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>kwargs[<span style=\"color: #808000; text-decoration-color: #808000\">\"scale_wrt_gas\"</span>] = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3739 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>                                                                              <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3740 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; text-decoration: underline\">self</span><span style=\"font-weight: bold; text-decoration: underline\">.accelerator.backward(loss, **kwargs)</span>                                     <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3741 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>                                                                              <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3742 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> loss.detach()                                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3743 </span>                                                                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">/home/sagemaker-user/.conda/envs/python_311/lib/python3.11/site-packages/accelerate/</span><span style=\"font-weight: bold\">accelerator.</span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"font-weight: bold\">py</span>:2734 in backward                                                                              <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2731 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> learning_rate <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.has_lomo_optimizer:                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2732 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.lomo_backward(loss, learning_rate)                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2733 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2734 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"font-weight: bold; text-decoration: underline\">loss.backward(**kwargs)</span>                                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2735 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2736 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">set_trigger</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>):                                                                <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2737 </span><span style=\"color: #bfbfbf; text-decoration-color: #bfbfbf\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">/home/sagemaker-user/.conda/envs/python_311/lib/python3.11/site-packages/torch/</span><span style=\"font-weight: bold\">_tensor.py</span>:581 in <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> backward                                                                                         <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 578 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>create_graph=create_graph,                                                <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 579 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>inputs=inputs,                                                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 580 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>)                                                                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 581 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"font-weight: bold; text-decoration: underline\">torch.autograd.backward(</span>                                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 582 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; text-decoration: underline\">self</span><span style=\"font-weight: bold; text-decoration: underline\">, gradient, retain_graph, create_graph, inputs=inputs</span>                     <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 583 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"font-weight: bold; text-decoration: underline\">)</span>                                                                                 <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 584 </span>                                                                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">/home/sagemaker-user/.conda/envs/python_311/lib/python3.11/site-packages/torch/autograd/</span><span style=\"font-weight: bold\">__init__</span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"font-weight: bold\">.py</span>:347 in backward                                                                              <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">344 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># The reason we repeat the same comment below is that</span>                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">345 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># some Python versions print out the first line of a multi-line function</span>               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">346 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># calls in the traceback and some print out the last line</span>                              <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>347 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"font-weight: bold; text-decoration: underline\">_engine_run_backward(</span>                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">348 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"font-weight: bold; text-decoration: underline\">tensors,</span>                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">349 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"font-weight: bold; text-decoration: underline\">grad_tensors_,</span>                                                                     <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">350 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"font-weight: bold; text-decoration: underline\">retain_graph,</span>                                                                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">/home/sagemaker-user/.conda/envs/python_311/lib/python3.11/site-packages/torch/autograd/</span><span style=\"font-weight: bold\">graph.py</span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> :825 in _engine_run_backward                                                                     <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">822 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> attach_logging_hooks:                                                               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">823 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">824 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>825 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> Variable._execution_engine.run_backward(  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Calls into the C++ engine to </span>   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">826 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>t_outputs, *args, **kwargs                                                     <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">827 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Calls into the C++ engine to run the backward pass</span>                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">828 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">finally</span>:                                                                               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;255;0;0m╭─\u001b[0m\u001b[38;2;255;0;0m──────────────────────────────\u001b[0m\u001b[38;2;255;0;0m \u001b[0m\u001b[1;38;2;255;0;0mTraceback \u001b[0m\u001b[1;2;38;2;255;0;0m(most recent call last)\u001b[0m\u001b[38;2;255;0;0m \u001b[0m\u001b[38;2;255;0;0m───────────────────────────────\u001b[0m\u001b[38;2;255;0;0m─╮\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m in <module>:1                                                                                    \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m1 \u001b[1;4mtrainer.train()\u001b[0m                                                                              \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[2m/home/sagemaker-user/.conda/envs/python_311/lib/python3.11/site-packages/transformers/\u001b[0m\u001b[1mtrainer.py\u001b[0m \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m :2241 in train                                                                                   \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m2238 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mfinally\u001b[0m:                                                                      \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m2239 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mhf_hub_utils.enable_progress_bars()                                       \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m2240 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m2241 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[1;4minner_training_loop(\u001b[0m                                                   \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m2242 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[1;4margs=args,\u001b[0m                                                                \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m2243 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[1;4mresume_from_checkpoint=resume_from_checkpoint,\u001b[0m                            \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m2244 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[1;4mtrial=trial,\u001b[0m                                                              \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[2m/home/sagemaker-user/.conda/envs/python_311/lib/python3.11/site-packages/transformers/\u001b[0m\u001b[1mtrainer.py\u001b[0m \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m :2548 in _inner_training_loop                                                                    \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m2545 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0m\u001b[94melse\u001b[0m contextlib.nullcontext                                       \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m2546 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m)                                                                     \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m2547 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mwith\u001b[0m context():                                                       \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m2548 \u001b[2m│   │   │   │   │   │   \u001b[0mtr_loss_step = \u001b[1;4;96mself\u001b[0m\u001b[1;4m.training_step(model, inputs, num_items_in_ba\u001b[0m  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m2549 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m                                                                      \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m2550 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mif\u001b[0m (                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m2551 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0margs.logging_nan_inf_filter                                       \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[2m/home/sagemaker-user/.conda/envs/python_311/lib/python3.11/site-packages/transformers/\u001b[0m\u001b[1mtrainer.py\u001b[0m \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m :3740 in training_step                                                                           \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m3737 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.accelerator.distributed_type == DistributedType.DEEPSPEED:            \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m3738 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mkwargs[\u001b[33m\"\u001b[0m\u001b[33mscale_wrt_gas\u001b[0m\u001b[33m\"\u001b[0m] = \u001b[94mFalse\u001b[0m                                           \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m3739 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                              \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m3740 \u001b[2m│   │   │   \u001b[0m\u001b[1;4;96mself\u001b[0m\u001b[1;4m.accelerator.backward(loss, **kwargs)\u001b[0m                                     \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m3741 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                              \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m3742 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m loss.detach()                                                          \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m3743 \u001b[0m                                                                                          \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[2m/home/sagemaker-user/.conda/envs/python_311/lib/python3.11/site-packages/accelerate/\u001b[0m\u001b[1maccelerator.\u001b[0m \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[1mpy\u001b[0m:2734 in backward                                                                              \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m2731 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m learning_rate \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mand\u001b[0m \u001b[96mself\u001b[0m.has_lomo_optimizer:                       \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m2732 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.lomo_backward(loss, learning_rate)                                       \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m2733 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m2734 \u001b[2m│   │   │   \u001b[0m\u001b[1;4mloss.backward(**kwargs)\u001b[0m                                                       \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m2735 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m2736 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m\u001b[90m \u001b[0m\u001b[92mset_trigger\u001b[0m(\u001b[96mself\u001b[0m):                                                                \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m2737 \u001b[0m\u001b[2;90m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                               \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[2m/home/sagemaker-user/.conda/envs/python_311/lib/python3.11/site-packages/torch/\u001b[0m\u001b[1m_tensor.py\u001b[0m:581 in \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m backward                                                                                         \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m 578 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mcreate_graph=create_graph,                                                \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m 579 \u001b[0m\u001b[2m│   │   │   │   \u001b[0minputs=inputs,                                                            \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m 580 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m 581 \u001b[2m│   │   \u001b[0m\u001b[1;4mtorch.autograd.backward(\u001b[0m                                                          \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m 582 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[1;4;96mself\u001b[0m\u001b[1;4m, gradient, retain_graph, create_graph, inputs=inputs\u001b[0m                     \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m 583 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[1;4m)\u001b[0m                                                                                 \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m 584 \u001b[0m                                                                                          \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[2m/home/sagemaker-user/.conda/envs/python_311/lib/python3.11/site-packages/torch/autograd/\u001b[0m\u001b[1m__init__\u001b[0m \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[1m.py\u001b[0m:347 in backward                                                                              \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m344 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# The reason we repeat the same comment below is that\u001b[0m                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m345 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# some Python versions print out the first line of a multi-line function\u001b[0m               \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m346 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# calls in the traceback and some print out the last line\u001b[0m                              \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m347 \u001b[2m│   \u001b[0m\u001b[1;4m_engine_run_backward(\u001b[0m                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m348 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[1;4mtensors,\u001b[0m                                                                           \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m349 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[1;4mgrad_tensors_,\u001b[0m                                                                     \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m350 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[1;4mretain_graph,\u001b[0m                                                                      \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[2m/home/sagemaker-user/.conda/envs/python_311/lib/python3.11/site-packages/torch/autograd/\u001b[0m\u001b[1mgraph.py\u001b[0m \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m :825 in _engine_run_backward                                                                     \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m822 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m attach_logging_hooks:                                                               \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m823 \u001b[0m\u001b[2m│   │   \u001b[0munregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)               \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m824 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mtry\u001b[0m:                                                                                   \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m825 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m Variable._execution_engine.run_backward(  \u001b[2m# Calls into the C++ engine to \u001b[0m   \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m826 \u001b[0m\u001b[2m│   │   │   \u001b[0mt_outputs, *args, **kwargs                                                     \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m827 \u001b[0m\u001b[2m│   │   \u001b[0m)  \u001b[2m# Calls into the C++ engine to run the backward pass\u001b[0m                            \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m828 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mfinally\u001b[0m:                                                                               \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb60749-f45f-4ae8-9883-94842279f618",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-09-05T01:01:45.487370Z",
     "iopub.status.idle": "2025-09-05T01:01:45.489001Z",
     "shell.execute_reply": "2025-09-05T01:01:45.488806Z",
     "shell.execute_reply.started": "2025-09-05T01:01:45.488786Z"
    }
   },
   "outputs": [],
   "source": [
    "eval_result = trainer.evaluate(eval_dataset=tokenized_dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1c769c-5718-4291-93ee-3fc0e3b31501",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_311_2",
   "language": "python",
   "name": "python_311_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
