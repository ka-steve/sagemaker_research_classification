{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10792a4c-7eba-44bc-a986-d272e47bd0df",
   "metadata": {},
   "source": [
    "Source: https://huggingface.co/docs/transformers/model_doc/auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2074e72e-717e-4bf3-a83d-2960eb4ee704",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install \"sagemaker>=2.250.0\" \"transformers>=4.55.2\" \"datasets==4.0.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f909cd8-9276-414e-9642-570d52ce237f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (AutoConfig, AutoModel, AutoTokenizer, AutoFeatureExtractor, \n",
    "    AutoProcessor, AutoModelForPreTraining, AutoModelForCausalLM, AutoModelForMaskedLM, \n",
    "    AutoModelForSeq2SeqLM, AutoModelForSequenceClassification, AutoModelForMultipleChoice, \n",
    "    AutoModelForNextSentencePrediction, AutoModelForTokenClassification, \n",
    "    AutoModelForQuestionAnswering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69be6bc7-a799-4436-9877-af1f787ce0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.55.2\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bb36597-49dc-4748-b8c8-6525cd14bc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.vocab_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb8fcecb-a8a8-4e45-8384-9206b8624a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.55.2\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 100\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "718209e2-468e-4662-99a0-5da167bab151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"output_attentions\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.55.2\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'foo': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config, unused_kwargs = AutoConfig.from_pretrained(\n",
    "    \"google-bert/bert-base-uncased\", output_attentions=True, foo=False, return_unused_kwargs=True\n",
    ")\n",
    "display(config)\n",
    "display(unused_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75116a0b-237e-4cc6-bd10-105bd3f59afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='google-bert/bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44272521-13fc-4441-af65-d0a038c02240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='google-bert/bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[mask]'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t30522: AddedToken(\"[mask]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just a dummy example on HOW to overwrite tokenizer parameters, but this specific change would make the tokenizer unusable:\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\", mask_token='[mask]')\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4001795-1d3a-466c-b0e8-ca6fe774726b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wav2Vec2FeatureExtractor {\n",
       "  \"do_normalize\": true,\n",
       "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
       "  \"feature_size\": 1,\n",
       "  \"padding_side\": \"right\",\n",
       "  \"padding_value\": 0.0,\n",
       "  \"return_attention_mask\": false,\n",
       "  \"sampling_rate\": 16000\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: Passing token=True is required when you want to use a private model.\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9a34d5b-b699-4c17-95bf-71a224ebcd65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wav2Vec2Processor:\n",
       "- feature_extractor: Wav2Vec2FeatureExtractor {\n",
       "  \"do_normalize\": true,\n",
       "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
       "  \"feature_size\": 1,\n",
       "  \"padding_side\": \"right\",\n",
       "  \"padding_value\": 0.0,\n",
       "  \"return_attention_mask\": false,\n",
       "  \"sampling_rate\": 16000\n",
       "}\n",
       "\n",
       "- tokenizer: Wav2Vec2CTCTokenizer(name_or_path='facebook/wav2vec2-base-960h', vocab_size=32, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t0: AddedToken(\"<pad>\", rstrip=True, lstrip=True, single_word=False, normalized=False, special=False),\n",
       "\t1: AddedToken(\"<s>\", rstrip=True, lstrip=True, single_word=False, normalized=False, special=False),\n",
       "\t2: AddedToken(\"</s>\", rstrip=True, lstrip=True, single_word=False, normalized=False, special=False),\n",
       "\t3: AddedToken(\"<unk>\", rstrip=True, lstrip=True, single_word=False, normalized=False, special=False),\n",
       "}\n",
       ")\n",
       "\n",
       "{\n",
       "  \"processor_class\": \"Wav2Vec2Processor\"\n",
       "}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: Passing token=True is required when you want to use a private model.\n",
    "processor = AutoProcessor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ffa9bfb-403d-4798-9c76-b21cba8fa82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wav2Vec2CTCTokenizer(name_or_path='facebook/wav2vec2-base-960h', vocab_size=32, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t0: AddedToken(\"<pad>\", rstrip=True, lstrip=True, single_word=False, normalized=False, special=False),\n",
       "\t1: AddedToken(\"<s>\", rstrip=True, lstrip=True, single_word=False, normalized=False, special=False),\n",
       "\t2: AddedToken(\"</s>\", rstrip=True, lstrip=True, single_word=False, normalized=False, special=False),\n",
       "\t3: AddedToken(\"<unk>\", rstrip=True, lstrip=True, single_word=False, normalized=False, special=False),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd5e1f78-43de-45dc-8f4c-f4d5af3e12fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(\"google-bert/bert-base-cased\")\n",
    "model = AutoModel.from_config(config)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14529f80-ce83-4939-a00f-e45f2f4c19ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update configuration during loading\n",
    "model = AutoModel.from_pretrained(\"google-bert/bert-base-cased\", output_attentions=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "309ab4d9-64c6-4fad-9165-24f84857eade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following models can be imported similarly as above:\n",
    "#    AutoModelForPreTraining, AutoModelForCausalLM, AutoModelForMaskedLM, \n",
    "#    AutoModelForSeq2SeqLM, AutoModelForSequenceClassification, AutoModelForMultipleChoice, \n",
    "#    AutoModelForNextSentencePrediction, AutoModelForTokenClassification, \n",
    "#    AutoModelForQuestionAnswering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1f60f2-9dc6-4369-a6e5-e8ccf8ea27e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
