{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fce94f89-1e40-49c3-86c0-ca08dcf4d51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "    current version: 25.3.0\n",
      "    latest version: 25.5.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c conda-forge conda\n",
      "\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Channels:\n",
      " - conda-forge\n",
      " - nvidia\n",
      " - pytorch\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "    current version: 25.3.0\n",
      "    latest version: 25.5.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c conda-forge conda\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%conda install numexpr>=2.8.4\n",
    "%conda install awswrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44aa8545-0d06-40c8-9381-56e914e9343e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import gzip\n",
    "import os\n",
    "import awswrangler as wr\n",
    "from tqdm import tqdm\n",
    "from botocore.exceptions import ClientError\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fc05eb-0f15-44bf-a0bd-181ff50269fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3b6758d-c2ec-4202-8f4e-a011fcac7bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing .gz files in bucket bsc-final-sagemaker-data-bucket with prefix 00_raw/papers/...\n",
      "Processing file: 00_raw/papers/papers-part0.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part0.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/1.07G [00:05<5:46:33, 51.6kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part0.jsonl.gz to papers-part0.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part0.jsonl.gz: 4.36GB [00:39, 109MB/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part0.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part0.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part0.jsonl\n",
      "Processing file: 00_raw/papers/papers-part1.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part1.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/574M [00:02<1:36:38, 99.0kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part1.jsonl.gz to papers-part1.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part1.jsonl.gz: 2.33GB [00:21, 110MB/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part1.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part1.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part1.jsonl\n",
      "Processing file: 00_raw/papers/papers-part10.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part10.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/1.07G [00:04<5:18:19, 56.2kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part10.jsonl.gz to papers-part10.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part10.jsonl.gz: 4.36GB [00:40, 108MB/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part10.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part10.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part10.jsonl\n",
      "Processing file: 00_raw/papers/papers-part11.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part11.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/574M [00:02<1:34:50, 101kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part11.jsonl.gz to papers-part11.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part11.jsonl.gz: 2.33GB [00:21, 109MB/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part11.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part11.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part11.jsonl\n",
      "Processing file: 00_raw/papers/papers-part12.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part12.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/529M [00:02<1:15:00, 117kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part12.jsonl.gz to papers-part12.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part12.jsonl.gz: 2.15GB [00:19, 111MB/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part12.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part12.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part12.jsonl\n",
      "Processing file: 00_raw/papers/papers-part13.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part13.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/1.07G [00:04<5:30:58, 54.1kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part13.jsonl.gz to papers-part13.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part13.jsonl.gz: 4.36GB [00:40, 108MB/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part13.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part13.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part13.jsonl\n",
      "Processing file: 00_raw/papers/papers-part14.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part14.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/1.07G [00:04<5:05:29, 58.6kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part14.jsonl.gz to papers-part14.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part14.jsonl.gz: 4.36GB [00:40, 107MB/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part14.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part14.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part14.jsonl\n",
      "Processing file: 00_raw/papers/papers-part15.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part15.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/655M [00:02<2:01:52, 89.5kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part15.jsonl.gz to papers-part15.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part15.jsonl.gz: 2.66GB [00:24, 109MB/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part15.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part15.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part15.jsonl\n",
      "Processing file: 00_raw/papers/papers-part16.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part16.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/571M [00:02<1:32:41, 103kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part16.jsonl.gz to papers-part16.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part16.jsonl.gz: 2.32GB [00:21, 108MB/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part16.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part16.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part16.jsonl\n",
      "Processing file: 00_raw/papers/papers-part17.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part17.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/368M [00:01<37:27, 163kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part17.jsonl.gz to papers-part17.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part17.jsonl.gz: 1.49GB [00:13, 111MB/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part17.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part17.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part17.jsonl\n",
      "Processing file: 00_raw/papers/papers-part18.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part18.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/1.07G [00:04<5:35:19, 53.4kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part18.jsonl.gz to papers-part18.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part18.jsonl.gz: 4.36GB [00:42, 101MB/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part18.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part18.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part18.jsonl\n",
      "Processing file: 00_raw/papers/papers-part19.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part19.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/1.07G [00:04<5:19:20, 56.0kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part19.jsonl.gz to papers-part19.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part19.jsonl.gz: 4.36GB [00:40, 108MB/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part19.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part19.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part19.jsonl\n",
      "Processing file: 00_raw/papers/papers-part2.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part2.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/623M [00:02<1:45:29, 98.4kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part2.jsonl.gz to papers-part2.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part2.jsonl.gz: 2.53GB [00:28, 90.1MB/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part2.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part2.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part2.jsonl\n",
      "Processing file: 00_raw/papers/papers-part20.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part20.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/337M [00:01<31:35, 177kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part20.jsonl.gz to papers-part20.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part20.jsonl.gz: 1.37GB [00:12, 112MB/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part20.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part20.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part20.jsonl\n",
      "Processing file: 00_raw/papers/papers-part21.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part21.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/1.07G [00:04<5:13:28, 57.1kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part21.jsonl.gz to papers-part21.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part21.jsonl.gz: 4.36GB [00:40, 107MB/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part21.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part21.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part21.jsonl\n",
      "Processing file: 00_raw/papers/papers-part22.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part22.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/1.07G [00:04<5:38:38, 52.8kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part22.jsonl.gz to papers-part22.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part22.jsonl.gz: 4.36GB [00:42, 102MB/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part22.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part22.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part22.jsonl\n",
      "Processing file: 00_raw/papers/papers-part23.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part23.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/1.07G [00:04<5:36:52, 53.1kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part23.jsonl.gz to papers-part23.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part23.jsonl.gz: 4.36GB [00:41, 105MB/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part23.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part23.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part23.jsonl\n",
      "Processing file: 00_raw/papers/papers-part24.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part24.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/1.07G [00:05<6:38:54, 44.9kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part24.jsonl.gz to papers-part24.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part24.jsonl.gz: 4.36GB [00:40, 108MB/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part24.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part24.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part24.jsonl\n",
      "Processing file: 00_raw/papers/papers-part25.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part25.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/643M [00:03<2:05:48, 85.1kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part25.jsonl.gz to papers-part25.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part25.jsonl.gz: 2.61GB [00:23, 110MB/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part25.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part25.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part25.jsonl\n",
      "Processing file: 00_raw/papers/papers-part26.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part26.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/1.07G [00:04<5:09:31, 57.8kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part26.jsonl.gz to papers-part26.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part26.jsonl.gz: 4.36GB [00:43, 100MB/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part26.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part26.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part26.jsonl\n",
      "Processing file: 00_raw/papers/papers-part27.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part27.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/1.07G [00:04<5:18:33, 56.2kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part27.jsonl.gz to papers-part27.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part27.jsonl.gz: 4.36GB [00:40, 109MB/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part27.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part27.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part27.jsonl\n",
      "Processing file: 00_raw/papers/papers-part28.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part28.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/1.07G [00:04<5:33:17, 53.7kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part28.jsonl.gz to papers-part28.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part28.jsonl.gz: 4.36GB [00:43, 101MB/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part28.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part28.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part28.jsonl\n",
      "Processing file: 00_raw/papers/papers-part29.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part29.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/579M [00:02<1:35:49, 101kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part29.jsonl.gz to papers-part29.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part29.jsonl.gz: 2.35GB [00:21, 109MB/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part29.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part29.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part29.jsonl\n",
      "Processing file: 00_raw/papers/papers-part3.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part3.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/1.07G [00:04<5:20:22, 55.8kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part3.jsonl.gz to papers-part3.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part3.jsonl.gz: 4.36GB [00:42, 102MB/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part3.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part3.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part3.jsonl\n",
      "Processing file: 00_raw/papers/papers-part30.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part30.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/1.07G [00:04<5:36:28, 53.2kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part30.jsonl.gz to papers-part30.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part30.jsonl.gz: 4.36GB [00:40, 107MB/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part30.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part30.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part30.jsonl\n",
      "Processing file: 00_raw/papers/papers-part31.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part31.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/1.07G [00:04<5:15:40, 56.7kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part31.jsonl.gz to papers-part31.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part31.jsonl.gz: 4.36GB [00:43, 101MB/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part31.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part31.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part31.jsonl\n",
      "Processing file: 00_raw/papers/papers-part32.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part32.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/1.07G [00:04<5:14:32, 56.9kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part32.jsonl.gz to papers-part32.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part32.jsonl.gz: 4.36GB [00:41, 106MB/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part32.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part32.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part32.jsonl\n",
      "Processing file: 00_raw/papers/papers-part33.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part33.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/610M [00:02<1:48:50, 93.4kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part33.jsonl.gz to papers-part33.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part33.jsonl.gz: 2.48GB [00:25, 99.0MB/s]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part33.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part33.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part33.jsonl\n",
      "Processing file: 00_raw/papers/papers-part34.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part34.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/648M [00:02<2:01:09, 89.1kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part34.jsonl.gz to papers-part34.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part34.jsonl.gz: 2.63GB [00:24, 108MB/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part34.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part34.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part34.jsonl\n",
      "Processing file: 00_raw/papers/papers-part35.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part35.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/1.07G [00:04<5:13:54, 57.0kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part35.jsonl.gz to papers-part35.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part35.jsonl.gz: 4.36GB [00:40, 107MB/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part35.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part35.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part35.jsonl\n",
      "Processing file: 00_raw/papers/papers-part36.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part36.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/1.07G [00:05<6:06:22, 48.8kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part36.jsonl.gz to papers-part36.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part36.jsonl.gz: 4.36GB [00:40, 107MB/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part36.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part36.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part36.jsonl\n",
      "Processing file: 00_raw/papers/papers-part37.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part37.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/643M [00:02<1:59:56, 89.3kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part37.jsonl.gz to papers-part37.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part37.jsonl.gz: 2.61GB [00:23, 109MB/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part37.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part37.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part37.jsonl\n",
      "Processing file: 00_raw/papers/papers-part38.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part38.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/653M [00:03<2:05:44, 86.5kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part38.jsonl.gz to papers-part38.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part38.jsonl.gz: 2.65GB [00:26, 99.5MB/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part38.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part38.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part38.jsonl\n",
      "Processing file: 00_raw/papers/papers-part39.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part39.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/1.07G [00:04<5:09:58, 57.7kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part39.jsonl.gz to papers-part39.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part39.jsonl.gz: 4.36GB [00:40, 107MB/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part39.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part39.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part39.jsonl\n",
      "Processing file: 00_raw/papers/papers-part4.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part4.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/632M [00:03<2:22:04, 74.1kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part4.jsonl.gz to papers-part4.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part4.jsonl.gz: 2.56GB [00:23, 109MB/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part4.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part4.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part4.jsonl\n",
      "Processing file: 00_raw/papers/papers-part40.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part40.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/1.07G [00:06<6:56:37, 42.9kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part40.jsonl.gz to papers-part40.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part40.jsonl.gz: 4.36GB [00:40, 107MB/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part40.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part40.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part40.jsonl\n",
      "Processing file: 00_raw/papers/papers-part41.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part41.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/1.07G [00:04<5:35:53, 53.3kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part41.jsonl.gz to papers-part41.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part41.jsonl.gz: 4.36GB [00:41, 106MB/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part41.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part41.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part41.jsonl\n",
      "Processing file: 00_raw/papers/papers-part42.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part42.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/591M [00:02<1:35:31, 103kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part42.jsonl.gz to papers-part42.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part42.jsonl.gz: 2.40GB [00:21, 110MB/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part42.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part42.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part42.jsonl\n",
      "Processing file: 00_raw/papers/papers-part43.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part43.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/1.07G [00:05<5:43:57, 52.0kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part43.jsonl.gz to papers-part43.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part43.jsonl.gz: 4.36GB [00:40, 107MB/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part43.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part43.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part43.jsonl\n",
      "Processing file: 00_raw/papers/papers-part44.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part44.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/642M [00:03<2:03:49, 86.3kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part44.jsonl.gz to papers-part44.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part44.jsonl.gz: 2.60GB [00:26, 98.0MB/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part44.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part44.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part44.jsonl\n",
      "Processing file: 00_raw/papers/papers-part45.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part45.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/571M [00:02<1:27:44, 108kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part45.jsonl.gz to papers-part45.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part45.jsonl.gz: 2.32GB [00:21, 109MB/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part45.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part45.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part45.jsonl\n",
      "Processing file: 00_raw/papers/papers-part46.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part46.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/581M [00:02<1:36:39, 100kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part46.jsonl.gz to papers-part46.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part46.jsonl.gz: 2.36GB [00:21, 110MB/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part46.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part46.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part46.jsonl\n",
      "Processing file: 00_raw/papers/papers-part47.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part47.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/567M [00:02<1:37:13, 97.2kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part47.jsonl.gz to papers-part47.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part47.jsonl.gz: 2.30GB [00:21, 109MB/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part47.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part47.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part47.jsonl\n",
      "Processing file: 00_raw/papers/papers-part48.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part48.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/661M [00:03<2:11:49, 83.5kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part48.jsonl.gz to papers-part48.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part48.jsonl.gz: 2.68GB [00:24, 109MB/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part48.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part48.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part48.jsonl\n",
      "Processing file: 00_raw/papers/papers-part49.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part49.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/589M [00:02<1:35:04, 103kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part49.jsonl.gz to papers-part49.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part49.jsonl.gz: 2.39GB [00:22, 106MB/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part49.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part49.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part49.jsonl\n",
      "Processing file: 00_raw/papers/papers-part5.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part5.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/711M [00:03<2:28:24, 79.8kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part5.jsonl.gz to papers-part5.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part5.jsonl.gz: 2.89GB [00:27, 107MB/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part5.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part5.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part5.jsonl\n",
      "Processing file: 00_raw/papers/papers-part50.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part50.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/594M [00:03<1:57:14, 84.3kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part50.jsonl.gz to papers-part50.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part50.jsonl.gz: 2.41GB [00:23, 100MB/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part50.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part50.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part50.jsonl\n",
      "Processing file: 00_raw/papers/papers-part51.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part51.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/1.07G [00:04<5:13:37, 57.1kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part51.jsonl.gz to papers-part51.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part51.jsonl.gz: 4.36GB [00:40, 107MB/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part51.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part51.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part51.jsonl\n",
      "Processing file: 00_raw/papers/papers-part52.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part52.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/1.07G [00:04<5:29:54, 54.2kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part52.jsonl.gz to papers-part52.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part52.jsonl.gz: 4.36GB [00:42, 101MB/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part52.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part52.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part52.jsonl\n",
      "Processing file: 00_raw/papers/papers-part53.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part53.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 170k/593M [00:02<2:25:32, 67.9kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part53.jsonl.gz to papers-part53.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part53.jsonl.gz: 2.41GB [00:22, 108MB/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part53.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part53.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part53.jsonl\n",
      "Processing file: 00_raw/papers/papers-part54.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part54.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/590M [00:02<1:41:38, 96.7kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part54.jsonl.gz to papers-part54.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part54.jsonl.gz: 2.39GB [00:22, 108MB/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part54.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part54.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part54.jsonl\n",
      "Processing file: 00_raw/papers/papers-part55.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part55.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/587M [00:02<1:43:07, 94.9kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part55.jsonl.gz to papers-part55.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part55.jsonl.gz: 2.38GB [00:24, 96.3MB/s]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part55.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part55.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part55.jsonl\n",
      "Processing file: 00_raw/papers/papers-part56.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part56.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/572M [00:02<1:31:59, 104kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part56.jsonl.gz to papers-part56.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part56.jsonl.gz: 2.32GB [00:21, 110MB/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part56.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part56.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part56.jsonl\n",
      "Processing file: 00_raw/papers/papers-part57.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part57.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/1.07G [00:04<5:18:05, 56.3kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part57.jsonl.gz to papers-part57.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part57.jsonl.gz: 4.36GB [00:41, 104MB/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part57.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part57.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part57.jsonl\n",
      "Processing file: 00_raw/papers/papers-part58.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part58.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/364M [00:01<40:28, 150kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part58.jsonl.gz to papers-part58.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part58.jsonl.gz: 1.48GB [00:14, 100MB/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part58.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part58.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part58.jsonl\n",
      "Processing file: 00_raw/papers/papers-part59.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part59.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/1.07G [00:04<5:20:25, 55.8kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part59.jsonl.gz to papers-part59.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part59.jsonl.gz: 4.36GB [00:41, 106MB/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part59.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part59.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part59.jsonl\n",
      "Processing file: 00_raw/papers/papers-part6.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part6.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/642M [00:03<2:18:25, 77.3kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part6.jsonl.gz to papers-part6.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part6.jsonl.gz: 2.61GB [00:24, 109MB/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part6.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part6.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part6.jsonl\n",
      "Processing file: 00_raw/papers/papers-part7.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part7.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/1.07G [00:05<5:53:50, 50.6kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part7.jsonl.gz to papers-part7.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part7.jsonl.gz: 4.36GB [00:41, 105MB/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part7.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part7.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part7.jsonl\n",
      "Processing file: 00_raw/papers/papers-part8.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part8.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/1.07G [00:04<5:09:49, 57.8kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part8.jsonl.gz to papers-part8.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part8.jsonl.gz: 4.36GB [00:40, 107MB/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part8.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part8.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part8.jsonl\n",
      "Processing file: 00_raw/papers/papers-part9.jsonl.gz\n",
      "Downloading 00_raw/papers/papers-part9.jsonl.gz from S3 bucket bsc-final-sagemaker-data-bucket...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 262k/1.07G [00:04<5:28:01, 54.5kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 00_raw/papers/papers-part9.jsonl.gz to papers-part9.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting papers-part9.jsonl.gz: 4.36GB [00:40, 108MB/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted content saved to papers-part9.jsonl\n",
      "Uploading extracted file to S3 bucket bsc-final-sagemaker-data-bucket with key 01_extracted/papers/papers-part9.jsonl...\n",
      "Uploaded extracted file to s3://bsc-final-sagemaker-data-bucket/01_extracted/papers/papers-part9.jsonl\n",
      "Starting Glue Crawler: s2__papers...\n",
      "Glue Crawler s2__papers is still running...\n",
      "Glue Crawler s2__papers is still running...\n",
      "Glue Crawler s2__papers is still running...\n",
      "Glue Crawler s2__papers is still running...\n",
      "Glue Crawler s2__papers is still running...\n",
      "Glue Crawler s2__papers is still running...\n",
      "Glue Crawler s2__papers is still running...\n",
      "Unexpected state for Glue Crawler s2__papers: STOPPING\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import gzip\n",
    "import os\n",
    "from botocore.exceptions import ClientError\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "class ProgressBar(tqdm):\n",
    "    \"\"\"Custom progress bar for S3 operations.\"\"\"\n",
    "    def update_to(self, bytes_transferred):\n",
    "        self.update(bytes_transferred - self.n)\n",
    "\n",
    "\n",
    "def download_file_with_progress(s3_client, bucket_name, key, local_file):\n",
    "    file_size = s3_client.head_object(Bucket=bucket_name, Key=key)['ContentLength']\n",
    "    with ProgressBar(total=file_size, unit=\"B\", unit_scale=True, desc=\"Downloading\") as progress_bar:\n",
    "        s3_client.download_file(\n",
    "            Bucket=bucket_name,\n",
    "            Key=key,\n",
    "            Filename=local_file,\n",
    "            Callback=progress_bar.update_to\n",
    "        )\n",
    "\n",
    "\n",
    "def upload_file_with_progress(s3_client, local_file, bucket_name, key):\n",
    "    file_size = os.path.getsize(local_file)\n",
    "    with ProgressBar(total=file_size, unit=\"B\", unit_scale=True, desc=\"Uploading\") as progress_bar:\n",
    "        s3_client.upload_file(\n",
    "            Filename=local_file,\n",
    "            Bucket=bucket_name,\n",
    "            Key=key,\n",
    "            Callback=progress_bar.update_to\n",
    "        )\n",
    "\n",
    "\n",
    "def register_file_in_glue(bucket_name, key, glue_database, glue_table, aws_region=\"eu-west-2\"):\n",
    "    \"\"\"\n",
    "    Registers the uploaded file in the Glue Catalog.\n",
    "\n",
    "    Args:\n",
    "        bucket_name (str): The name of the S3 bucket.\n",
    "        key (str): The key of the file in the S3 bucket.\n",
    "        glue_database (str): The Glue database name.\n",
    "        glue_table (str): The Glue table name.\n",
    "        aws_region (str): The AWS region.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    glue_client = boto3.client(\"glue\", region_name=aws_region)\n",
    "    s3_path = f\"s3://{bucket_name}/{key}\"\n",
    "\n",
    "    try:\n",
    "        # Check if the table exists\n",
    "        glue_client.get_table(DatabaseName=glue_database, Name=glue_table)\n",
    "        print(f\"Table {glue_table} already exists in Glue. Updating table...\")\n",
    "    except glue_client.exceptions.EntityNotFoundException:\n",
    "        print(f\"Table {glue_table} does not exist. Creating table...\")\n",
    "\n",
    "        # Define the table schema\n",
    "        table_input = {\n",
    "            \"Name\": glue_table,\n",
    "            \"StorageDescriptor\": {\n",
    "                \"Columns\": [\n",
    "                    {\"Name\": \"field1\", \"Type\": \"string\"},  # Replace with actual schema\n",
    "                    {\"Name\": \"field2\", \"Type\": \"string\"},  # Replace with actual schema\n",
    "                ],\n",
    "                \"Location\": f\"s3://{bucket_name}/{key.rsplit('/', 1)[0]}/\",\n",
    "                \"InputFormat\": \"org.apache.hadoop.mapred.TextInputFormat\",\n",
    "                \"OutputFormat\": \"org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat\",\n",
    "                \"SerdeInfo\": {\n",
    "                    \"SerializationLibrary\": \"org.openx.data.jsonserde.JsonSerDe\",\n",
    "                    \"Parameters\": {\"paths\": \"field1,field2\"}  # Replace with actual fields\n",
    "                },\n",
    "            },\n",
    "            \"TableType\": \"EXTERNAL_TABLE\",\n",
    "            \"Parameters\": {\"classification\": \"json\"},\n",
    "        }\n",
    "\n",
    "        # Create the table\n",
    "        glue_client.create_table(DatabaseName=glue_database, TableInput=table_input)\n",
    "        print(f\"Table {glue_table} created in Glue.\")\n",
    "\n",
    "    # Add the new file to the table's location\n",
    "    print(f\"File {s3_path} registered in Glue table {glue_table}.\")\n",
    "\n",
    "\n",
    "def download_extract_upload_s3(bucket_name, gz_key, extracted_key, s3_output_key, glue_database, glue_table, aws_region):\n",
    "    s3_client = boto3.client(\"s3\", region_name=aws_region)\n",
    "    local_extracted_file = extracted_key.split('/')[-1]\n",
    "    local_gz_file = f'{local_extracted_file}.gz'\n",
    "\n",
    "    try:\n",
    "        print(f\"Downloading {gz_key} from S3 bucket {bucket_name}...\")\n",
    "        if not os.path.exists(local_gz_file):\n",
    "            download_file_with_progress(s3_client, bucket_name, gz_key, local_gz_file)\n",
    "            print(f\"Downloaded {gz_key} to {local_gz_file}\")\n",
    "        else:\n",
    "            print(f\"{local_gz_file} already exists, skipping download\")\n",
    "\n",
    "        if not os.path.exists(local_extracted_file):\n",
    "            with gzip.open(local_gz_file, 'rt') as gz_file:\n",
    "                gz_file_size = os.path.getsize(local_gz_file)\n",
    "                with tqdm(total=gz_file_size, unit='B', unit_scale=True, desc=f'Extracting {local_gz_file}') as progress_bar:\n",
    "                    with open(local_extracted_file, 'w') as extracted_file:\n",
    "                        while chunk := gz_file.read(8192):\n",
    "                            extracted_file.write(chunk)\n",
    "                            progress_bar.update(len(chunk))\n",
    "            print(f'Extracted content saved to {local_extracted_file}')\n",
    "        else:\n",
    "            print(f\"{local_extracted_file} already extracted, skipping extraction\")\n",
    "\n",
    "        print(f\"Uploading extracted file to S3 bucket {bucket_name} with key {s3_output_key}...\")\n",
    "        upload_file_with_progress(s3_client, local_extracted_file, bucket_name, s3_output_key)\n",
    "        print(f\"Uploaded extracted file to s3://{bucket_name}/{s3_output_key}\")\n",
    "\n",
    "        # Register the file in Glue\n",
    "        # register_file_in_glue(bucket_name, extracted_key, glue_database, glue_table, aws_region)\n",
    "\n",
    "    except ClientError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    # finally:\n",
    "        # if os.path.exists(local_gz_file):\n",
    "        #    os.remove(local_gz_file)\n",
    "        # if os.path.exists(local_extracted_file):\n",
    "        #    os.remove(local_extracted_file)\n",
    "\n",
    "import boto3\n",
    "import gzip\n",
    "import os\n",
    "from botocore.exceptions import ClientError\n",
    "from tqdm import tqdm\n",
    "\n",
    "class ProgressBar(tqdm):\n",
    "    \"\"\"Custom progress bar for S3 operations.\"\"\"\n",
    "    def update_to(self, bytes_transferred):\n",
    "        self.update(bytes_transferred - self.n)\n",
    "\n",
    "\n",
    "def download_file_with_progress(s3_client, bucket_name, key, local_file):\n",
    "    file_size = s3_client.head_object(Bucket=bucket_name, Key=key)['ContentLength']\n",
    "    with ProgressBar(total=file_size, unit=\"B\", unit_scale=True, desc=\"Downloading\") as progress_bar:\n",
    "        s3_client.download_file(\n",
    "            Bucket=bucket_name,\n",
    "            Key=key,\n",
    "            Filename=local_file,\n",
    "            Callback=progress_bar.update_to\n",
    "        )\n",
    "\n",
    "\n",
    "def register_file_in_glue(bucket_name, key, glue_database, glue_table, aws_region=\"eu-west-2\"):\n",
    "    \"\"\"\n",
    "    Registers the uploaded file in the Glue Catalog.\n",
    "\n",
    "    Args:\n",
    "        bucket_name (str): The name of the S3 bucket.\n",
    "        key (str): The key of the file in the S3 bucket.\n",
    "        glue_database (str): The Glue database name.\n",
    "        glue_table (str): The Glue table name.\n",
    "        aws_region (str): The AWS region.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    glue_client = boto3.client(\"glue\", region_name=aws_region)\n",
    "    s3_path = f\"s3://{bucket_name}/{key}\"\n",
    "\n",
    "    try:\n",
    "        # Check if the table exists\n",
    "        glue_client.get_table(DatabaseName=glue_database, Name=glue_table)\n",
    "        print(f\"Table {glue_table} already exists in Glue. Updating table...\")\n",
    "    except glue_client.exceptions.EntityNotFoundException:\n",
    "        print(f\"Table {glue_table} does not exist. Creating table...\")\n",
    "\n",
    "        # Define the table schema\n",
    "        table_input = {\n",
    "            \"Name\": glue_table,\n",
    "            \"StorageDescriptor\": {\n",
    "                \"Columns\": [\n",
    "                    {\"Name\": \"field1\", \"Type\": \"string\"},  # Replace with actual schema\n",
    "                    {\"Name\": \"field2\", \"Type\": \"string\"},  # Replace with actual schema\n",
    "                ],\n",
    "                \"Location\": f\"s3://{bucket_name}/{key.rsplit('/', 1)[0]}/\",\n",
    "                \"InputFormat\": \"org.apache.hadoop.mapred.TextInputFormat\",\n",
    "                \"OutputFormat\": \"org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat\",\n",
    "                \"SerdeInfo\": {\n",
    "                    \"SerializationLibrary\": \"org.openx.data.jsonserde.JsonSerDe\",\n",
    "                    \"Parameters\": {\"paths\": \"field1,field2\"}  # Replace with actual fields\n",
    "                },\n",
    "            },\n",
    "            \"TableType\": \"EXTERNAL_TABLE\",\n",
    "            \"Parameters\": {\"classification\": \"json\"},\n",
    "        }\n",
    "\n",
    "        # Create the table\n",
    "        glue_client.create_table(DatabaseName=glue_database, TableInput=table_input)\n",
    "        print(f\"Table {glue_table} created in Glue.\")\n",
    "\n",
    "    # Add the new file to the table's location\n",
    "    print(f\"File {s3_path} registered in Glue table {glue_table}.\")\n",
    "\n",
    "\n",
    "def download_extract_upload_s3(bucket_name, gz_key, extracted_key, s3_output_key, aws_region='eu-west-2'):\n",
    "    s3_client = boto3.client(\"s3\", region_name=aws_region)\n",
    "    local_extracted_file = extracted_key.split('/')[-1]\n",
    "    local_gz_file = f'{local_extracted_file}.gz'\n",
    "\n",
    "    try:\n",
    "        print(f\"Downloading {gz_key} from S3 bucket {bucket_name}...\")\n",
    "        if not os.path.exists(local_gz_file):\n",
    "            download_file_with_progress(s3_client, bucket_name, gz_key, local_gz_file)\n",
    "            print(f\"Downloaded {gz_key} to {local_gz_file}\")\n",
    "        else:\n",
    "            print(f\"{local_gz_file} already exists, skipping download\")\n",
    "\n",
    "        if not os.path.exists(local_extracted_file):\n",
    "            with gzip.open(local_gz_file, 'rt') as gz_file:\n",
    "                gz_file_size = os.path.getsize(local_gz_file)\n",
    "                with tqdm(total=gz_file_size, unit='B', unit_scale=True, desc=f'Extracting {local_gz_file}') as progress_bar:\n",
    "                    with open(local_extracted_file, 'w') as extracted_file:\n",
    "                        while chunk := gz_file.read(8192):\n",
    "                            extracted_file.write(chunk)\n",
    "                            progress_bar.update(len(chunk))\n",
    "            print(f'Extracted content saved to {local_extracted_file}')\n",
    "        else:\n",
    "            print(f\"{local_extracted_file} already extracted, skipping extraction\")\n",
    "\n",
    "        print(f\"Uploading extracted file to S3 bucket {bucket_name} with key {s3_output_key}...\")\n",
    "        s3_client.upload_file(\n",
    "            Filename=local_extracted_file,\n",
    "            Bucket=bucket_name,\n",
    "            Key=s3_output_key\n",
    "        )\n",
    "        print(f\"Uploaded extracted file to s3://{bucket_name}/{s3_output_key}\")\n",
    "\n",
    "\n",
    "    except ClientError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    finally:\n",
    "        if os.path.exists(local_gz_file):\n",
    "            os.remove(local_gz_file)\n",
    "        if os.path.exists(local_extracted_file):\n",
    "            os.remove(local_extracted_file)\n",
    "\n",
    "def run_glue_crawler(crawler_name, aws_region=\"eu-west-2\"):\n",
    "    \"\"\"\n",
    "    Runs a Glue Crawler to refresh the Glue Catalog.\n",
    "\n",
    "    Args:\n",
    "        crawler_name (str): The name of the Glue Crawler.\n",
    "        aws_region (str): The AWS region where the Glue Crawler is located.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    glue_client = boto3.client(\"glue\", region_name=aws_region)\n",
    "\n",
    "    try:\n",
    "        print(f\"Starting Glue Crawler: {crawler_name}...\")\n",
    "        glue_client.start_crawler(Name=crawler_name)\n",
    "\n",
    "        # Wait for the crawler to complete\n",
    "        while True:\n",
    "            response = glue_client.get_crawler(Name=crawler_name)\n",
    "            state = response[\"Crawler\"][\"State\"]\n",
    "            if state == \"READY\":\n",
    "                print(f\"Glue Crawler {crawler_name} has completed.\")\n",
    "                break\n",
    "            elif state == \"RUNNING\":\n",
    "                print(f\"Glue Crawler {crawler_name} is still running...\")\n",
    "            else:\n",
    "                print(f\"Unexpected state for Glue Crawler {crawler_name}: {state}\")\n",
    "                break\n",
    "            time.sleep(10)  # Wait for 10 seconds before checking again\n",
    "\n",
    "    except ClientError as e:\n",
    "        print(f\"Error running Glue Crawler {crawler_name}: {e}\")\n",
    "\n",
    "def extract_all_files(bucket_name, prefix, s3_output_prefix, glue_database, glue_table, min_index=0, max_index=100000, aws_region=\"eu-west-2\"):\n",
    "    s3_client = boto3.client(\"s3\", region_name=aws_region)\n",
    "\n",
    "    try:\n",
    "        \n",
    "        print(f\"Listing .gz files in bucket {bucket_name} with prefix {prefix}...\")\n",
    "        response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n",
    "        if \"Contents\" not in response:\n",
    "            print(\"No files found.\")\n",
    "            return\n",
    "\n",
    "        counter = 0\n",
    "        for obj in response[\"Contents\"]:\n",
    "            if counter >= min_index and counter < max_index:\n",
    "                gz_key = obj[\"Key\"]\n",
    "                if gz_key.endswith(\".gz\"):\n",
    "                    extracted_key = gz_key.replace(\".gz\", \"\").split('/')[-1]\n",
    "                    s3_output_key = f'{s3_output_prefix}{extracted_key}'\n",
    "                    print(f\"Processing file: {gz_key}\")\n",
    "                    download_extract_upload_s3(bucket_name, gz_key, extracted_key, s3_output_key)\n",
    "            counter += 1\n",
    "            \n",
    "        crawler_name = f\"{glue_database}__{glue_table}\"  # Example: \"s2__papers\"\n",
    "        run_glue_crawler(crawler_name)\n",
    "\n",
    "    except ClientError as e:\n",
    "        print(f\"Error listing files in S3: {e}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "bucket_name = \"bsc-final-sagemaker-data-bucket\"\n",
    "prefix = \"00_raw/papers/\"  # Prefix for the .gz files\n",
    "s3_output_prefix = \"01_extracted/papers/\"  # S3 prefix for the output dataset\n",
    "glue_database = \"s2\"  # Glue database name\n",
    "glue_table = \"papers\"  # Glue table name\n",
    "\n",
    "extract_all_files(bucket_name, prefix, s3_output_prefix, glue_database, glue_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4faa9374-3645-46f9-a199-b04e0c174eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Glue Crawler: s2__papers...\n",
      "Glue Crawler s2__papers is still running...\n",
      "Glue Crawler s2__papers is still running...\n",
      "Glue Crawler s2__papers is still running...\n",
      "Glue Crawler s2__papers is still running...\n",
      "Glue Crawler s2__papers is still running...\n",
      "Glue Crawler s2__papers is still running...\n",
      "Glue Crawler s2__papers is still running...\n",
      "Glue Crawler s2__papers is still running...\n",
      "Glue Crawler s2__papers is still running...\n",
      "Glue Crawler s2__papers is still running...\n",
      "Glue Crawler s2__papers is still running...\n",
      "Glue Crawler s2__papers is still running...\n",
      "Glue Crawler s2__papers is still running...\n",
      "Glue Crawler s2__papers is still running...\n",
      "Unexpected state for Glue Crawler s2__papers: STOPPING\n"
     ]
    }
   ],
   "source": [
    "run_glue_crawler('s2__papers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57312698-5404-453a-aa60-f3b45be4f07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "class ProgressBar(tqdm):\n",
    "    \"\"\"Custom progress bar for S3 operations.\"\"\"\n",
    "\n",
    "    def update_to(self, bytes_transferred):\n",
    "        self.update(bytes_transferred - self.n)\n",
    "\n",
    "\n",
    "def download_file_with_progress(s3_client, bucket_name, key, local_file):\n",
    "    \"\"\"\n",
    "    Downloads a file from S3 with a progress bar.\n",
    "\n",
    "    Args:\n",
    "        s3_client: The boto3 S3 client.\n",
    "        bucket_name (str): The name of the S3 bucket.\n",
    "        key (str): The key of the file in the S3 bucket.\n",
    "        local_file (str): The local file path to save the downloaded file.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    file_size = s3_client.head_object(Bucket=bucket_name, Key=key)['ContentLength']\n",
    "    with ProgressBar(total=file_size, unit=\"B\", unit_scale=True, desc=\"Downloading\") as progress_bar:\n",
    "        s3_client.download_file(\n",
    "            Bucket=bucket_name,\n",
    "            Key=key,\n",
    "            Filename=local_file,\n",
    "            Callback=progress_bar.update_to\n",
    "        )\n",
    "\n",
    "\n",
    "def download_extract_save_to_athena(counter, bucket_name, gz_key, s3_output_prefix, glue_database, glue_table, aws_region=\"eu-west-2\"):\n",
    "    \"\"\"\n",
    "    Downloads a .gz file from S3, extracts its contents, and saves it to S3 as a dataset using awswrangler.\n",
    "\n",
    "    Args:\n",
    "        bucket_name (str): The name of the S3 bucket.\n",
    "        gz_key (str): The key of the .gz file in the S3 bucket.\n",
    "        s3_output_prefix (str): The S3 prefix where the dataset will be saved.\n",
    "        glue_database (str): The Glue database name.\n",
    "        glue_table (str): The Glue table name.\n",
    "        aws_region (str): The AWS region of the S3 bucket.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    s3_client = boto3.client(\"s3\", region_name=aws_region)\n",
    "    extracted_key = gz_key.replace(\".gz\", \"\")\n",
    "    local_extracted_file = extracted_key.split('/')[-1]\n",
    "    local_gz_file = f'{local_extracted_file}.gz'\n",
    "\n",
    "    try:\n",
    "        # Step 1: Download the .gz file from S3\n",
    "        print(f\"Downloading {gz_key} from S3 bucket {bucket_name}...\")\n",
    "        if not os.path.exists(local_gz_file):\n",
    "            download_file_with_progress(s3_client, bucket_name, gz_key, local_gz_file)\n",
    "            print(f\"Downloaded {gz_key} to {local_gz_file}\")\n",
    "        else:\n",
    "            print(f\"{local_gz_file} already exists, skipping download\")\n",
    "\n",
    "        # Step 2: Extract the .gz file\n",
    "        if not os.path.exists(local_extracted_file):\n",
    "            print(f\"Extracting {local_gz_file}...\")\n",
    "            with gzip.open(local_gz_file, 'rt') as gz_file:\n",
    "                gz_file_size = os.path.getsize(local_gz_file)\n",
    "                with tqdm(total=gz_file_size, unit='B', unit_scale=True, desc=f'Extracting {local_gz_file}') as progress_bar:\n",
    "                    with open(local_extracted_file, 'w') as extracted_file:\n",
    "                        while chunk := gz_file.read(8192):\n",
    "                            extracted_file.write(chunk)\n",
    "                            progress_bar.update(len(chunk))\n",
    "            print(f'Extracted content saved to {local_extracted_file}')\n",
    "        else:\n",
    "            print(f\"{local_extracted_file} already extracted, skipping extraction\")\n",
    "\n",
    "        # Step 3: Save the extracted file to S3 as a dataset and register it in Athena\n",
    "        print(f\"Saving {local_extracted_file} to S3 as a dataset and registering it in Athena...\")\n",
    "        s3_output_path = f\"s3://{bucket_name}/{s3_output_prefix}\"\n",
    "\n",
    "        chunk_counter = 0\n",
    "        with pd.read_json(local_extracted_file, lines=True, chunksize=10000) as reader:\n",
    "            for chunk in reader:\n",
    "                print(f'Reading chunk#{chunk_counter} of file #{counter}')\n",
    "                display(chunk.head(1))\n",
    "                mode = 'append'\n",
    "                if counter == 0 and chunk_counter == 0:\n",
    "                    mode = 'overwrite'\n",
    "\n",
    "                # Save the DataFrame to S3 as a dataset\n",
    "                wr.s3.to_json(\n",
    "                    df=chunk,\n",
    "                    path=s3_output_path,\n",
    "                    dataset=True,\n",
    "                    database=glue_database,\n",
    "                    table=glue_table,\n",
    "                    mode=mode\n",
    "                )\n",
    "                chunk_counter += 1\n",
    "\n",
    "#         # Read the JSONL file into a Pandas DataFrame\n",
    "#         # df = pd.read_json(local_extracted_file, lines=True)\n",
    "#         mode = 'append'\n",
    "#         if counter == 0:\n",
    "#             mode = 'overwrite'\n",
    "#     \n",
    "#         # Save the DataFrame to S3 as a dataset\n",
    "#         wr.s3.to_json(\n",
    "#             df=df,\n",
    "#             path=s3_output_path,\n",
    "#             dataset=True,\n",
    "#             database=glue_database,\n",
    "#             table=glue_table,\n",
    "#             mode=mode\n",
    "#         )\n",
    "        print(f\"Dataset saved to {s3_output_path} and registered in Athena (Glue database: {glue_database}, table: {glue_table}).\")\n",
    "\n",
    "    except ClientError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "#     finally:\n",
    "#         # Clean up local temporary files\n",
    "#         if os.path.exists(local_gz_file):\n",
    "#             os.remove(local_gz_file)\n",
    "#         if os.path.exists(local_extracted_file):\n",
    "#             os.remove(local_extracted_file)\n",
    "\n",
    "\n",
    "def extract_all_files(bucket_name, prefix, s3_output_prefix, glue_database, glue_table, aws_region=\"eu-west-2\", min_index=0, max_index=100000):\n",
    "    \"\"\"\n",
    "    Processes all .gz files in an S3 bucket with a given prefix.\n",
    "\n",
    "    Args:\n",
    "        bucket_name (str): The name of the S3 bucket.\n",
    "        prefix (str): The prefix of the .gz files in the S3 bucket.\n",
    "        s3_output_prefix (str): The S3 prefix where the dataset will be saved.\n",
    "        glue_database (str): The Glue database name.\n",
    "        glue_table (str): The Glue table name.\n",
    "        aws_region (str): The AWS region of the S3 bucket.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    s3_client = boto3.client(\"s3\", region_name=aws_region)\n",
    "\n",
    "    try:\n",
    "        # List all .gz files in the bucket with the given prefix\n",
    "        print(f\"Listing .gz files in bucket {bucket_name} with prefix {prefix}...\")\n",
    "        response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n",
    "        if \"Contents\" not in response:\n",
    "            print(\"No files found.\")\n",
    "            return\n",
    "\n",
    "        counter = 0\n",
    "        for obj in response[\"Contents\"]:\n",
    "            if counter >= min_index and counter < max_index:\n",
    "                gz_key = obj[\"Key\"]\n",
    "                if gz_key.endswith(\".gz\"):\n",
    "                    print(f\"Processing file: {gz_key}\")\n",
    "                    download_extract_save_to_athena(counter, bucket_name, gz_key, s3_output_prefix, glue_database, glue_table, aws_region)\n",
    "            counter += 1\n",
    "\n",
    "    except ClientError as e:\n",
    "        print(f\"Error listing files in S3: {e}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "bucket_name = \"bsc-final-sagemaker-data-bucket\"\n",
    "prefix = \"00_raw/papers/\"  # Prefix for the .gz files\n",
    "s3_output_prefix = \"01_extracted/papers/\"  # S3 prefix for the output dataset\n",
    "glue_database = \"s2\"  # Glue database name\n",
    "glue_table = \"papers\"  # Glue table name\n",
    "aws_region = \"eu-west-2\"  # AWS region of the bucket\n",
    "\n",
    "extract_all_files(bucket_name, prefix, s3_output_prefix, glue_database, glue_table, aws_region, 0, 1)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
