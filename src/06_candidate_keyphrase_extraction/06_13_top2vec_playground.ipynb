{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4f121b4-b7c9-45dc-838d-fbeca2010c68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-13T19:59:56.557067Z",
     "iopub.status.busy": "2025-09-13T19:59:56.556818Z",
     "iopub.status.idle": "2025-09-13T20:00:01.310331Z",
     "shell.execute_reply": "2025-09-13T20:00:01.309802Z",
     "shell.execute_reply.started": "2025-09-13T19:59:56.557047Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "config.py loaded: v0.1\n",
      "utils.py loaded: v0.2.12\n",
      "utils.py loaded: v0.2.12\n",
      "config.py loaded: v0.1\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import importlib\n",
    "import transformers\n",
    "import torch\n",
    "import pathlib\n",
    "import smart_open\n",
    "import awswrangler as wr\n",
    "from IPython.display import display\n",
    "from sagemaker.huggingface.processing import HuggingFaceProcessor\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import FrameworkProcessor\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.session import get_execution_role\n",
    "\n",
    "\n",
    "# Adding ../01_modules or ./01_modules to the system path so that we can load modules from \n",
    "# there as well\n",
    "if '__file__' in globals():\n",
    "    script_dir = pathlib.Path(__file__).parent.resolve()\n",
    "else:\n",
    "    script_dir = pathlib.Path().absolute()\n",
    "modules_path_in_dev = os.path.abspath(os.path.join(script_dir, '..', '01_modules'))\n",
    "modules_path_in_prod = os.path.abspath(os.path.join(script_dir, '01_modules'))\n",
    "if os.path.exists(modules_path_in_dev):\n",
    "    sys.path.append(modules_path_in_dev)\n",
    "if os.path.exists(modules_path_in_prod):\n",
    "    sys.path.append(modules_path_in_prod)\n",
    "\n",
    "\n",
    "# # Jupyter only reads a local module the first time after \n",
    "# # kernel start. Re-running a cell with \n",
    "# # \"from mymodulename import *\" would not change\n",
    "# # anything, even if the imported module has since changed.\n",
    "# # As a workaround, we need to directly load the module, \n",
    "# # use importlib.reload to reload it and then import * \n",
    "import utils\n",
    "_ = importlib.reload(utils)\n",
    "import config\n",
    "_ = importlib.reload(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b7767a8-952f-47c4-b400-6ca3bf32468a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-13T15:26:34.188039Z",
     "iopub.status.busy": "2025-09-13T15:26:34.187875Z",
     "iopub.status.idle": "2025-09-13T15:26:43.301421Z",
     "shell.execute_reply": "2025-09-13T15:26:43.300926Z",
     "shell.execute_reply.started": "2025-09-13T15:26:34.188023Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m116.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n",
      " :: :: TIMELOGGER STARTED :: | since_start: 0.00 seconds | since_last: 0.00 seconds :: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n@conference{schopf_etal_kdir22,\\nauthor={Tim Schopf and Simon Klimek and Florian Matthes},\\ntitle={PatternRank: Leveraging Pretrained Language Models and Part of Speech for Unsupervised Keyphrase Extraction},\\nbooktitle={Proceedings of the 14th International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management (IC3K 2022) - KDIR},\\nyear={2022},\\npages={243-248},\\npublisher={SciTePress},\\norganization={INSTICC},\\ndoi={10.5220/0011546600003335},\\nisbn={978-989-758-614-9},\\nissn={2184-3228},\\n}\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, json, re, argparse, math\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import spacy\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from keybert import KeyBERT\n",
    "from keyphrase_vectorizers import KeyphraseCountVectorizer\n",
    "import spacy.cli\n",
    "spacy_model = 'en_core_web_sm'\n",
    "spacy.cli.download(spacy_model)\n",
    "spacy_exclude = ['parser', 'attribute_ruler', 'lemmatizer', 'ner', 'textcat']\n",
    "nlp = spacy.load(spacy_model, exclude=spacy_exclude)\n",
    "timelogger = utils.TimeLogger()\n",
    "\"\"\"\n",
    "@conference{schopf_etal_kdir22,\n",
    "author={Tim Schopf and Simon Klimek and Florian Matthes},\n",
    "title={PatternRank: Leveraging Pretrained Language Models and Part of Speech for Unsupervised Keyphrase Extraction},\n",
    "booktitle={Proceedings of the 14th International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management (IC3K 2022) - KDIR},\n",
    "year={2022},\n",
    "pages={243-248},\n",
    "publisher={SciTePress},\n",
    "organization={INSTICC},\n",
    "doi={10.5220/0011546600003335},\n",
    "isbn={978-989-758-614-9},\n",
    "issn={2184-3228},\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6abd9ca-1256-43cd-9a9f-7b95887d54bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-13T20:00:04.432898Z",
     "iopub.status.busy": "2025-09-13T20:00:04.432631Z",
     "iopub.status.idle": "2025-09-13T20:00:09.044163Z",
     "shell.execute_reply": "2025-09-13T20:00:09.043659Z",
     "shell.execute_reply.started": "2025-09-13T20:00:04.432877Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As was noted earlier, we formed our dataset utilizing the existing relations present in SNOMED CT. T'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database_name = '02_stg'\n",
    "table_name = 'stg_filtered_work_chapters_methodology_single'\n",
    "id_columns = ['work_id']\n",
    "text_column_name = 'chapter_text'\n",
    "text_batch_size = 1000\n",
    "\n",
    "utils.pd_set_options(cols=100)\n",
    "id_column_names = ', '.join(id_columns)\n",
    "# TODO: pagination\n",
    "texts_df = wr.athena.read_sql_query(f\"\"\"\n",
    "    SELECT\n",
    "        {id_column_names}, {text_column_name} \n",
    "    FROM\n",
    "        \"{database_name}\".{table_name}\n",
    "    ORDER BY\n",
    "        {id_column_names}\n",
    "    LIMIT\n",
    "        {text_batch_size}\n",
    "    \"\"\",\n",
    "    database_name\n",
    ")\n",
    "texts_only_list = texts_df[text_column_name].tolist()\n",
    "texts_only_list[0][0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce627b11-1035-41b1-93d1-2f01ba438e36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-13T20:00:43.188798Z",
     "iopub.status.busy": "2025-09-13T20:00:43.188525Z",
     "iopub.status.idle": "2025-09-13T20:01:31.526223Z",
     "shell.execute_reply": "2025-09-13T20:01:31.525568Z",
     "shell.execute_reply.started": "2025-09-13T20:00:43.188777Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-13 20:00:43,190 - top2vec - INFO - Pre-processing documents for training\n",
      "/home/sagemaker-user/.conda/envs/python_311/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2025-09-13 20:00:44,283 - top2vec - INFO - Creating vocabulary embedding\n",
      "Embedding vocabulary: 100%|██████████| 30/30 [00:04<00:00,  6.79it/s]\n",
      "2025-09-13 20:00:49,394 - top2vec - INFO - Create contextualized document embeddings\n",
      "Embedding documents: 100%|██████████| 32/32 [00:05<00:00,  6.27it/s]\n",
      "1000it [00:00, 6228.96it/s]\n",
      "2025-09-13 20:00:58,720 - top2vec - INFO - Creating lower dimension embedding of documents\n",
      "2025-09-13 20:01:25,665 - top2vec - INFO - Finding dense areas of documents\n",
      "2025-09-13 20:01:25,849 - top2vec - INFO - Finding topics\n",
      "Smoothing document token embeddings: 100%|██████████| 1000/1000 [00:04<00:00, 239.10it/s]\n",
      "Calculating document topic distributions: 100%|██████████| 1000/1000 [00:00<00:00, 3626.91it/s]\n"
     ]
    }
   ],
   "source": [
    "from top2vec import Top2Vec\n",
    "\n",
    "# Create a Contextual Top2Vec model\n",
    "top2vec_model = Top2Vec(documents=texts_only_list,\n",
    "                        ngram_vocab=True,\n",
    "                        contextual_top2vec=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ecb38a7-a093-4ae3-9471-f9b8038b0e56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-13T20:02:39.730747Z",
     "iopub.status.busy": "2025-09-13T20:02:39.730447Z",
     "iopub.status.idle": "2025-09-13T20:02:39.734878Z",
     "shell.execute_reply": "2025-09-13T20:02:39.734319Z",
     "shell.execute_reply.started": "2025-09-13T20:02:39.730723Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top2vec_model.get_num_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c9cdad6-787d-4ed6-81e1-5225373f1f02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-13T20:03:04.324045Z",
     "iopub.status.busy": "2025-09-13T20:03:04.323787Z",
     "iopub.status.idle": "2025-09-13T20:03:04.328399Z",
     "shell.execute_reply": "2025-09-13T20:03:04.327920Z",
     "shell.execute_reply.started": "2025-09-13T20:03:04.324026Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([12278, 10966,  9748,  7952,  7732,  7462,  6623,  6484,  6196,\n",
       "         5744,  5673,  5604,  5354,  5303,  5177,  5165,  5115,  4913,\n",
       "         4708,  4650,  4454,  4339,  4127,  3936,  3783,  3267,  3233,\n",
       "         3104,  3082,  3080,  2949,  2917,  2851,  2814,  2697,  2685,\n",
       "         2600,  2566,  2561,  2471,  2471,  2410,  2299,  2271,  2253,\n",
       "         2180,  2175,  2170,  2112,  2106,  2100,  2037,  1986,  1955,\n",
       "         1921,  1920,  1815,  1793,  1764,  1700,  1684,  1657,  1657,\n",
       "         1637,  1627,  1539,  1533,  1486,  1480,  1476,  1451,  1399,\n",
       "         1365,  1357,  1343,  1343,  1148,  1136,  1068,  1062,  1050,\n",
       "          988,   968,   853,   821,   781,   769,   744]),\n",
       " array([79, 53, 75,  0, 76, 85, 82, 62, 47, 51, 44, 29, 80, 74, 63, 84, 57,\n",
       "        20, 55, 35, 70, 73, 13, 24, 68,  3, 37, 14,  1, 58, 87, 18, 46, 72,\n",
       "        15, 81, 27, 56, 38, 11, 67, 22, 50,  9, 60,  2, 83, 30,  6,  7, 36,\n",
       "        77, 71, 39, 43, 64, 23, 17, 41, 86, 65, 78, 31, 52, 34, 48, 28, 42,\n",
       "        61, 40, 10, 66, 45,  4, 16,  5, 32, 59, 21, 49, 19, 26, 33, 69, 25,\n",
       "        54, 12,  8]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top2vec_model.get_topic_sizes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8261be8-f524-4c57-86be-2b87e45187c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-13T20:04:41.688244Z",
     "iopub.status.busy": "2025-09-13T20:04:41.687984Z",
     "iopub.status.idle": "2025-09-13T20:04:41.693032Z",
     "shell.execute_reply": "2025-09-13T20:04:41.692561Z",
     "shell.execute_reply.started": "2025-09-13T20:04:41.688224Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['research methodology', 'qualitative research', 'action research',\n",
       "        'qualitative data', 'grounded theory', 'research questions',\n",
       "        'software measurement', 'present study', 'digital repository',\n",
       "        'software engineering', 'software development',\n",
       "        'provisioning model', 'scientific research', 'pilot study',\n",
       "        'software system', 'design science', 'proposed methodology',\n",
       "        'content analysis', 'questionnaire was', 'to analyze',\n",
       "        'sub processes', 'case study', 'data sources', 'itbm ontology',\n",
       "        'design modeling', 'web archiving', 'object oriented',\n",
       "        'are summarized', 'this study', 'expert interviews',\n",
       "        'evaluation metrics', 'engineering design',\n",
       "        'security practitioners', 'google scholar', 'data collection',\n",
       "        'icase tools', 'case studies', 'review process',\n",
       "        'means clustering', 'to develop', 'knowledge architecture',\n",
       "        'professional competence', 'information retrieval',\n",
       "        'social science', 'main objective', 'source synonym', 'copy tasks',\n",
       "        'test cases', 'service oriented', 'data persistence'], dtype='<U25'),\n",
       " array([0.34984928, 0.30723757, 0.29029366, 0.28580925, 0.27875155,\n",
       "        0.27704373, 0.27309743, 0.2727351 , 0.27254632, 0.27246866,\n",
       "        0.2721973 , 0.27119803, 0.27059314, 0.2697082 , 0.26746088,\n",
       "        0.26480317, 0.26184803, 0.25883448, 0.25641316, 0.25635326,\n",
       "        0.2561118 , 0.25547865, 0.25334916, 0.25301823, 0.25258306,\n",
       "        0.2468943 , 0.24446693, 0.24374671, 0.24100967, 0.24078813,\n",
       "        0.24077277, 0.24050124, 0.23954625, 0.23856312, 0.23788498,\n",
       "        0.23458566, 0.23363847, 0.23324883, 0.23087025, 0.2308459 ,\n",
       "        0.22936688, 0.22886318, 0.22859092, 0.22668682, 0.22625144,\n",
       "        0.22543944, 0.22458908, 0.22445582, 0.22408372, 0.22187953],\n",
       "       dtype=float32),\n",
       " 79)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_words, word_scores, topic_nums = top2vec_model.get_topics()\n",
    "topic_words[79], word_scores[79], topic_nums[79]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15e6b91c-e67b-4562-bd42-c7c43e4928bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-13T20:05:19.717178Z",
     "iopub.status.busy": "2025-09-13T20:05:19.716920Z",
     "iopub.status.idle": "2025-09-13T20:05:19.721977Z",
     "shell.execute_reply": "2025-09-13T20:05:19.721482Z",
     "shell.execute_reply.started": "2025-09-13T20:05:19.717159Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['sensed images', 'feature extraction', 'optical flow',\n",
       "        'extracted features', 'region fidelity', 'image enhancement',\n",
       "        'semi supervised', 'saliency map', 'each pixel', 'medical images',\n",
       "        'spatial resolution', 'satellite images', 'sparse coding',\n",
       "        'feature maps', 'feature vectors', 'similarity measure',\n",
       "        'remote sensing', 'pattern recognition', 'classification tasks',\n",
       "        'intensity saliency', 'features among', 'brain images',\n",
       "        'eye tracker', 'instance learning', 'sensory data',\n",
       "        'conjugate features', 'binary mask', 'visual abstraction',\n",
       "        'feature map', 'machine svm', 'nearest neighbor',\n",
       "        'labeled dataset', 'feature selection', 'rgb based',\n",
       "        'proposed algorithm', 'support vector', 'similarity scores',\n",
       "        'cover image', 'deep multi', 'supervised classification',\n",
       "        'clustering method', 'spectrum saliency', 'brain image',\n",
       "        'convolutional layers', 'product features',\n",
       "        'classification accuracy', 'feature vector', 'median filter',\n",
       "        'svm classifier', 'feature space'], dtype='<U25'),\n",
       " array([0.37113747, 0.28777748, 0.27698404, 0.27147165, 0.26943028,\n",
       "        0.26772547, 0.26460794, 0.2631526 , 0.26008335, 0.25742033,\n",
       "        0.24630716, 0.24416658, 0.24360435, 0.23608957, 0.23566133,\n",
       "        0.22790778, 0.22448798, 0.22320564, 0.22029787, 0.21762268,\n",
       "        0.21689892, 0.21569233, 0.21535401, 0.21425943, 0.2137453 ,\n",
       "        0.21374422, 0.21183519, 0.20829983, 0.20637518, 0.20013638,\n",
       "        0.19639885, 0.19501957, 0.19371991, 0.19249287, 0.1914939 ,\n",
       "        0.19062859, 0.19046521, 0.189224  , 0.18810451, 0.18763182,\n",
       "        0.1875463 , 0.18688382, 0.18458404, 0.18415602, 0.18408516,\n",
       "        0.18405814, 0.18373321, 0.18314643, 0.18272169, 0.18245983],\n",
       "       dtype=float32),\n",
       " 53)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_words, word_scores, topic_nums = top2vec_model.get_topics()\n",
    "topic_words[53], word_scores[53], topic_nums[53]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4382f5e-cbb5-4a61-b1ff-270d5c687764",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-13T20:06:47.246353Z",
     "iopub.status.busy": "2025-09-13T20:06:47.246088Z",
     "iopub.status.idle": "2025-09-13T20:06:47.264876Z",
     "shell.execute_reply": "2025-09-13T20:06:47.263963Z",
     "shell.execute_reply.started": "2025-09-13T20:06:47.246334Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array(['research methodology', 'qualitative research', 'action research',\n",
       "         'qualitative data', 'grounded theory', 'research questions',\n",
       "         'software measurement', 'present study', 'digital repository',\n",
       "         'software engineering', 'software development',\n",
       "         'provisioning model', 'scientific research', 'pilot study',\n",
       "         'software system', 'design science', 'proposed methodology',\n",
       "         'content analysis', 'questionnaire was', 'to analyze',\n",
       "         'sub processes', 'case study', 'data sources', 'itbm ontology',\n",
       "         'design modeling', 'web archiving', 'object oriented',\n",
       "         'are summarized', 'this study', 'expert interviews',\n",
       "         'evaluation metrics', 'engineering design',\n",
       "         'security practitioners', 'google scholar', 'data collection',\n",
       "         'icase tools', 'case studies', 'review process',\n",
       "         'means clustering', 'to develop', 'knowledge architecture',\n",
       "         'professional competence', 'information retrieval',\n",
       "         'social science', 'main objective', 'source synonym', 'copy tasks',\n",
       "         'test cases', 'service oriented', 'data persistence'], dtype='<U25'),\n",
       "  array(['survey instrument', 'questionnaire was', 'students who',\n",
       "         'research methodology', 'present study', 'software system',\n",
       "         'software measurement', 'qualitative research',\n",
       "         'pedagogical conditions', 'qualitative data', 'evaluation metrics',\n",
       "         'presenting curriculum', 'mobile learning', 'data collection',\n",
       "         'data acquisition', 'this study', 'data bank', 'data sources',\n",
       "         'research questions', 'pilot study', 'web archiving',\n",
       "         'itbm ontology', 'professional competence', 'provisioning model',\n",
       "         'software development', 'learning rate', 'content analysis',\n",
       "         'digital literacy', 'digital repository', 'higher education',\n",
       "         'grounded theory', 'software engineering', 'action research',\n",
       "         'to assess', 'mobile device', 'information retrieval',\n",
       "         'cloud provider', 'means clustering', 'usability testing',\n",
       "         'cloud service', 'google scholar', 'proposed methodology',\n",
       "         'by applying', 'design modeling', 'information security',\n",
       "         'undergraduate students', 'to analyze', 'were analyzed',\n",
       "         'sample size', 'operating system'], dtype='<U25'),\n",
       "  array(['software measurement', 'object oriented', 'sub processes',\n",
       "         'design modeling', 'provisioning model', 'umls semantic',\n",
       "         'prototype application', 'software system', 'engineering design',\n",
       "         'software engineering', 'proposed framework', 'processing step',\n",
       "         'named entities', 'semantic constraints', 'programming language',\n",
       "         'visual abstraction', 'software development', 'design science',\n",
       "         'copy tasks', 'research methodology', 'functional model',\n",
       "         'icase tools', 'itbm ontology', 'evaluation metrics',\n",
       "         'proposed methodology', 'comsdm method', 'concurrent system',\n",
       "         'programming languages', 'micro architectural', 'data collection',\n",
       "         'objective function', 'semantic types', 'service oriented',\n",
       "         'usability testing', 'google analytics', 'user interface',\n",
       "         'knowledge architecture', 'code reusability', 'data persistence',\n",
       "         'physical computing', 'data acquisition', 'coupling measures',\n",
       "         'classification tasks', 'section describes', 'formal description',\n",
       "         'to analyze', 'semi structured', 'operating system',\n",
       "         'proposed system', 'pre processing'], dtype='<U25'),\n",
       "  array(['data acquisition', 'grounded theory', 'digital repository',\n",
       "         'information security', 'digital forensic', 'software measurement',\n",
       "         'software system', 'research methodology', 'data sources',\n",
       "         'to analyze', 'icase tools', 'digital literacy', 'to investigate',\n",
       "         'action research', 'cyber security', 'data bank',\n",
       "         'security practitioners', 'cybersecurity culture',\n",
       "         'data persistence', 'operating system', 'sub processes',\n",
       "         'secret information', 'data centers', 'copy tasks',\n",
       "         'human computer', 'software engineering', 'test cases',\n",
       "         'secondary data', 'access control', 'research questions',\n",
       "         'questionnaire was', 'data collection', 'engineering design',\n",
       "         'design science', 'vs test', 'review process', 'to assess',\n",
       "         'to validate', 'pilot study', 'object oriented',\n",
       "         'software development', 'evaluation metrics',\n",
       "         'proposed methodology', 'extracted features', 'region fidelity',\n",
       "         'proposed framework', 'virtual machine', 'content analysis',\n",
       "         'contextual information', 'expert interviews'], dtype='<U25'),\n",
       "  array(['questionnaire was', 'evaluation metrics', 'survey instrument',\n",
       "         'contextual information', 'usability testing', 'mobile device',\n",
       "         'software system', 'content analysis', 'information retrieval',\n",
       "         'mobile devices', 'was evaluated', 'design modeling',\n",
       "         'grounded theory', 'similarity scores', 'research methodology',\n",
       "         'are presented', 'user interface', 'software measurement',\n",
       "         'each participant', 'to analyze', 'qualitative data',\n",
       "         'human computer', 'semantic types', 'copy tasks',\n",
       "         'mobile learning', 'correspond to', 'were conducted',\n",
       "         'descriptive statistics', 'participants were', 'itbm ontology',\n",
       "         'umls semantic', 'review process', 'characterized by',\n",
       "         'data acquisition', 'was conducted', 'to evaluate',\n",
       "         'for evaluating', 'to facilitate', 'were analyzed',\n",
       "         'section describes', 'to assess', 'are summarized', 'shared task',\n",
       "         'participant under', 'classification tasks',\n",
       "         'qualitative research', 'features among', 'functional model',\n",
       "         'data collection', 'semantic constraints'], dtype='<U25'),\n",
       "  array(['visual abstraction', 'visualization techniques', 'axial coding',\n",
       "         'feature maps', 'qualitative data', 'object oriented',\n",
       "         'feature map', 'flow chart', 'clustering method', 'data sets',\n",
       "         'research methodology', 'semantic types', 'descriptive statistics',\n",
       "         'extracted features', 'tib patterns', 'to analyze',\n",
       "         'three dimensional', 'user interface', 'sub processes',\n",
       "         'programming language', 'feature extraction', 'icase tools',\n",
       "         'data collection', 'training data', 'data persistence',\n",
       "         'hierarchical clustering', 'labeled dataset', 'data sources',\n",
       "         'were analyzed', 'google analytics', 'objective function',\n",
       "         'topological patterns', 'software system', 'means clustering',\n",
       "         'processing step', 'spatial resolution', 'itbm ontology',\n",
       "         'design modeling', 'information retrieval', 'content analysis',\n",
       "         'classification tasks', 'contextual information', 'feature space',\n",
       "         'focus groups', 'umls semantic', 'synonym vector',\n",
       "         'dimensional space', 'are summarized', 'programming languages',\n",
       "         'semantic constraints'], dtype='<U25'),\n",
       "  array(['security practitioners', 'information security',\n",
       "         'cybersecurity culture', 'access control', 'cyber security',\n",
       "         'software measurement', 'secret information', 'design science',\n",
       "         'data bank', 'data centers', 'google analytics',\n",
       "         'questionnaire was', 'software system', 'data acquisition',\n",
       "         'human computer', 'pull requests', 'engineering design',\n",
       "         'expert interviews', 'smart monitoring', 'design modeling',\n",
       "         'software engineering', 'user interface', 'web archiving',\n",
       "         'monitoring service', 'web archives', 'research questions',\n",
       "         'cloud computing', 'main objective', 'computer science',\n",
       "         'mobile devices', 'research methodology', 'data sources',\n",
       "         'to analyze', 'object oriented', 'digital repository',\n",
       "         'risk factors', 'data collection', 'usability testing',\n",
       "         'frequent itemsets', 'icase tools', 'itbm ontology',\n",
       "         'frequent itemset', 'service oriented', 'evaluation metrics',\n",
       "         'provisioning model', 'anomaly detection', 'cpu core',\n",
       "         'mobile device', 'potential risk', 'were analyzed'], dtype='<U25'),\n",
       "  array(['sub processes', 'software measurement', 'object oriented',\n",
       "         'icase tools', 'semantic constraints', 'design modeling',\n",
       "         'software system', 'classification tasks', 'objective function',\n",
       "         'software engineering', 'evaluation metrics', 'concurrent system',\n",
       "         'decision tree', 'copy tasks', 'umls semantic',\n",
       "         'engineering design', 'programming language',\n",
       "         'software development', 'data mining', 'functional model',\n",
       "         'processing step', 'visual abstraction', 'programming languages',\n",
       "         'comsdm method', 'proposed methodology', 'prototype application',\n",
       "         'proposed framework', 'provisioning model', 'parameter sets',\n",
       "         'initiator matrix', 'itbm ontology', 'design science',\n",
       "         'shared task', 'google analytics', 'access control',\n",
       "         'knowledge architecture', 'research methodology', 'user interface',\n",
       "         'bayesian classifier', 'training examples', 'flow chart',\n",
       "         'usability testing', 'coupling measures', 'anomaly detection',\n",
       "         'semantic types', 'svm classifier', 'code reusability',\n",
       "         'temporal outliers', 'pre processing', 'training data'],\n",
       "        dtype='<U25'),\n",
       "  array(['survey instrument', 'questionnaire was', 'digital repository',\n",
       "         'data sources', 'web archives', 'web archiving', 'data collection',\n",
       "         'students who', 'pull requests', 'data persistence',\n",
       "         'research questions', 'were analyzed', 'sample size', 'data bank',\n",
       "         'data acquisition', 'academic year', 'correspond to',\n",
       "         'were conducted', 'experimental group', 'to facilitate',\n",
       "         'qualitative data', 'by applying', 'survey was', 'interviews were',\n",
       "         'th semester', 'google scholar', 'data centers',\n",
       "         'sampling technique', 'secondary data', 'information retrieval',\n",
       "         'were collected', 'pull request', 'graduate students',\n",
       "         'participants were', 'information security', 'labeled samples',\n",
       "         'be applied', 'higher education', 'expert interviews',\n",
       "         'after applying', 'action research', 'digital literacy',\n",
       "         'are presented', 'google analytics', 'training data', 'this study',\n",
       "         'mailing list', 'our experiments', 'to retrieve', 'to assess'],\n",
       "        dtype='<U25'),\n",
       "  array(['pedagogical conditions', 'students who',\n",
       "         'professional competence', 'presenting curriculum',\n",
       "         'present study', 'experimental group', 'questionnaire was',\n",
       "         'th semester', 'academic year', 'pilot study', 'this study',\n",
       "         'each participant', 'were conducted', 'undergraduate students',\n",
       "         'were analyzed', 'participant under', 'higher education',\n",
       "         'was conducted', 'level courses', 'testing phase',\n",
       "         'training examples', 'test set', 'to analyze', 'participants were',\n",
       "         'prototype application', 'graduate students', 'test sets',\n",
       "         'research methodology', 'engineering design', 'teaching aids',\n",
       "         'test cases', 'proposed methodology', 'software engineering',\n",
       "         'after applying', 'maximum posteriori', 'research questions',\n",
       "         'descriptive statistics', 'experimented with', 'sub processes',\n",
       "         'classical conjunction', 'are extracted', 'scientific research',\n",
       "         'all experiments', 'three stages', 'experimental results',\n",
       "         'concurrent system', 'to evaluate', 'by applying',\n",
       "         'mobile learning', 'fitness function'], dtype='<U25')],\n",
       " [array([0.34984928, 0.30723757, 0.29029366, 0.28580925, 0.27875155,\n",
       "         0.27704373, 0.27309743, 0.2727351 , 0.27254632, 0.27246866,\n",
       "         0.2721973 , 0.27119803, 0.27059314, 0.2697082 , 0.26746088,\n",
       "         0.26480317, 0.26184803, 0.25883448, 0.25641316, 0.25635326,\n",
       "         0.2561118 , 0.25547865, 0.25334916, 0.25301823, 0.25258306,\n",
       "         0.2468943 , 0.24446693, 0.24374671, 0.24100967, 0.24078813,\n",
       "         0.24077277, 0.24050124, 0.23954625, 0.23856312, 0.23788498,\n",
       "         0.23458566, 0.23363847, 0.23324883, 0.23087025, 0.2308459 ,\n",
       "         0.22936688, 0.22886318, 0.22859092, 0.22668682, 0.22625144,\n",
       "         0.22543944, 0.22458908, 0.22445582, 0.22408372, 0.22187953],\n",
       "        dtype=float32),\n",
       "  array([0.30367368, 0.3003864 , 0.27400243, 0.2733949 , 0.2621177 ,\n",
       "         0.26159266, 0.2615493 , 0.2548447 , 0.2540932 , 0.25398922,\n",
       "         0.2506465 , 0.24674547, 0.24617891, 0.24585423, 0.24342424,\n",
       "         0.24063194, 0.2393197 , 0.23625138, 0.23551156, 0.23522064,\n",
       "         0.23518075, 0.23489879, 0.23418237, 0.2333339 , 0.22730792,\n",
       "         0.22725274, 0.22558028, 0.2255163 , 0.22546041, 0.22526279,\n",
       "         0.22477885, 0.22352791, 0.22195718, 0.22184512, 0.21947157,\n",
       "         0.21938224, 0.21869971, 0.21860391, 0.21816897, 0.21708593,\n",
       "         0.21699935, 0.21634704, 0.21627522, 0.21543255, 0.21420887,\n",
       "         0.21338038, 0.21273336, 0.21222775, 0.21207428, 0.21195015],\n",
       "        dtype=float32),\n",
       "  array([0.3142614 , 0.30098268, 0.29480585, 0.2868766 , 0.27727088,\n",
       "         0.2516506 , 0.2504479 , 0.24979213, 0.24773552, 0.24344401,\n",
       "         0.23831475, 0.23815861, 0.23737963, 0.2360339 , 0.23518164,\n",
       "         0.23101228, 0.22922392, 0.22910191, 0.22724389, 0.22242384,\n",
       "         0.22185695, 0.22135317, 0.22132026, 0.21662952, 0.21583487,\n",
       "         0.21463159, 0.21428601, 0.21222526, 0.20780523, 0.20690162,\n",
       "         0.2066171 , 0.2065269 , 0.20604363, 0.20294982, 0.19824108,\n",
       "         0.19793376, 0.19609937, 0.19486864, 0.19442445, 0.19203325,\n",
       "         0.19028534, 0.19011517, 0.1892774 , 0.1875353 , 0.18623625,\n",
       "         0.18582761, 0.18525171, 0.18358606, 0.1819284 , 0.18133871],\n",
       "        dtype=float32),\n",
       "  array([0.26179913, 0.2388672 , 0.23419397, 0.23378968, 0.22694725,\n",
       "         0.2241747 , 0.22279282, 0.21413618, 0.21254668, 0.21232331,\n",
       "         0.20508058, 0.20407087, 0.2038984 , 0.20107035, 0.1964074 ,\n",
       "         0.19422038, 0.19404905, 0.19288936, 0.19264954, 0.1897275 ,\n",
       "         0.18818557, 0.18815258, 0.1865244 , 0.18628377, 0.18534209,\n",
       "         0.18302639, 0.18240102, 0.1823362 , 0.18163797, 0.18080513,\n",
       "         0.17762773, 0.17723724, 0.17390828, 0.17389208, 0.17369395,\n",
       "         0.17357545, 0.17293052, 0.1721112 , 0.17051592, 0.16965605,\n",
       "         0.16832612, 0.16824853, 0.16766284, 0.16650695, 0.16566452,\n",
       "         0.16562225, 0.1652541 , 0.16466983, 0.16377756, 0.16368821],\n",
       "        dtype=float32),\n",
       "  array([0.2641261 , 0.2585406 , 0.2428213 , 0.22962065, 0.22763939,\n",
       "         0.22620015, 0.22539587, 0.22508979, 0.22457083, 0.2219712 ,\n",
       "         0.22123824, 0.21948367, 0.21443054, 0.21395515, 0.20727268,\n",
       "         0.20726556, 0.20726544, 0.20524809, 0.20468172, 0.2018227 ,\n",
       "         0.19912624, 0.19903341, 0.19881007, 0.19688807, 0.19637786,\n",
       "         0.19618408, 0.19599283, 0.19542935, 0.19180073, 0.19052604,\n",
       "         0.19028069, 0.18977137, 0.18923625, 0.18884453, 0.18835494,\n",
       "         0.18771923, 0.18696338, 0.18674937, 0.18573195, 0.18521929,\n",
       "         0.18462951, 0.18438274, 0.18378845, 0.18252526, 0.18194602,\n",
       "         0.18186244, 0.18177222, 0.18101782, 0.18088482, 0.18047404],\n",
       "        dtype=float32),\n",
       "  array([0.26632193, 0.25239065, 0.22923647, 0.20680334, 0.20464943,\n",
       "         0.20286517, 0.19944116, 0.19837236, 0.19832268, 0.19533104,\n",
       "         0.19417207, 0.1929025 , 0.19038907, 0.19008593, 0.18139814,\n",
       "         0.18136902, 0.18113866, 0.18080923, 0.18055972, 0.18035108,\n",
       "         0.17895651, 0.17791714, 0.17705037, 0.17597802, 0.1748722 ,\n",
       "         0.17455246, 0.17272243, 0.1722377 , 0.17130339, 0.16978446,\n",
       "         0.16861688, 0.1676001 , 0.16521595, 0.16213244, 0.16195656,\n",
       "         0.16128218, 0.15936327, 0.15855126, 0.15709336, 0.15693253,\n",
       "         0.15593618, 0.15530114, 0.15514168, 0.15507191, 0.15478899,\n",
       "         0.15390263, 0.15332328, 0.1531867 , 0.15271616, 0.15261702],\n",
       "        dtype=float32),\n",
       "  array([0.37179512, 0.3464376 , 0.2686554 , 0.2633096 , 0.25744203,\n",
       "         0.23687835, 0.22849557, 0.2256636 , 0.22476962, 0.22107372,\n",
       "         0.21714829, 0.21531466, 0.21077766, 0.20993535, 0.20617639,\n",
       "         0.2043067 , 0.20224407, 0.20195818, 0.20076965, 0.20045057,\n",
       "         0.19798836, 0.19576026, 0.19492905, 0.19376238, 0.19364524,\n",
       "         0.1912073 , 0.18976547, 0.18741147, 0.18740757, 0.18666802,\n",
       "         0.18549542, 0.18343355, 0.18319604, 0.18309647, 0.18307815,\n",
       "         0.18270427, 0.18258852, 0.18190295, 0.18185481, 0.18160728,\n",
       "         0.18143094, 0.18047564, 0.17962661, 0.17839906, 0.17751947,\n",
       "         0.17630494, 0.17608212, 0.1754079 , 0.17388237, 0.17190586],\n",
       "        dtype=float32),\n",
       "  array([0.29201278, 0.28627473, 0.28029516, 0.26362735, 0.25751823,\n",
       "         0.25155696, 0.24465838, 0.24444692, 0.23975535, 0.23552339,\n",
       "         0.23109043, 0.22794698, 0.22499181, 0.22453558, 0.22078113,\n",
       "         0.22048959, 0.21947591, 0.21171282, 0.20992287, 0.20657451,\n",
       "         0.20601065, 0.20548266, 0.20333046, 0.20106706, 0.19897185,\n",
       "         0.19859172, 0.19663952, 0.19655725, 0.19547565, 0.19413951,\n",
       "         0.1934367 , 0.19323024, 0.19037071, 0.18999252, 0.1899668 ,\n",
       "         0.1871504 , 0.18544497, 0.1847944 , 0.18454865, 0.18447286,\n",
       "         0.18370241, 0.18278663, 0.1824991 , 0.18113108, 0.1810654 ,\n",
       "         0.18056522, 0.18011402, 0.17899519, 0.17887169, 0.17840035],\n",
       "        dtype=float32),\n",
       "  array([0.3393351 , 0.29582426, 0.29302064, 0.27687177, 0.2759915 ,\n",
       "         0.2749515 , 0.26918158, 0.26175842, 0.25941756, 0.258899  ,\n",
       "         0.25811282, 0.25354806, 0.2533828 , 0.25043604, 0.24542005,\n",
       "         0.24384497, 0.24261172, 0.23520404, 0.23479329, 0.23238581,\n",
       "         0.2320683 , 0.23127976, 0.22946313, 0.22679207, 0.22612602,\n",
       "         0.2254273 , 0.22512867, 0.22461551, 0.22449271, 0.22261614,\n",
       "         0.22258994, 0.22115503, 0.22060719, 0.21991533, 0.21717525,\n",
       "         0.21622571, 0.21515523, 0.21462089, 0.21384698, 0.21264589,\n",
       "         0.21257596, 0.21109551, 0.21082096, 0.20894876, 0.20856313,\n",
       "         0.20804866, 0.20788194, 0.20760982, 0.20756331, 0.20729034],\n",
       "        dtype=float32),\n",
       "  array([0.2856785 , 0.26107052, 0.25674486, 0.24584727, 0.2399488 ,\n",
       "         0.23739909, 0.22644809, 0.22495848, 0.21550398, 0.20395887,\n",
       "         0.20252098, 0.20142798, 0.19977012, 0.19961308, 0.19700783,\n",
       "         0.18849081, 0.18762752, 0.18397662, 0.1834213 , 0.18242326,\n",
       "         0.18094574, 0.18040654, 0.1802484 , 0.17950681, 0.17816521,\n",
       "         0.17655878, 0.17563541, 0.17411597, 0.16935126, 0.16808183,\n",
       "         0.16712166, 0.16345306, 0.16075532, 0.1601431 , 0.16013606,\n",
       "         0.15939438, 0.15903386, 0.15900505, 0.15861677, 0.15778592,\n",
       "         0.1560475 , 0.1532139 , 0.15270972, 0.15262341, 0.15190357,\n",
       "         0.15140124, 0.15095064, 0.15077396, 0.15074244, 0.1503433 ],\n",
       "        dtype=float32)],\n",
       " array([0.34984924, 0.27339499, 0.22242382, 0.21413618, 0.20727268,\n",
       "        0.19417216, 0.18549543, 0.18544509, 0.17563394, 0.17411605]),\n",
       " array([79, 85, 70, 64, 75, 45, 77, 71, 83, 78]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_words, word_scores, topic_scores, topic_nums = top2vec_model.search_topics(keywords=['research methodology'], num_topics=10)\n",
    "topic_words, word_scores, topic_scores, topic_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a247ea0d-0ed4-41b1-b474-06a7c09ef580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf31133-5f78-41c8-bda9-cca851f1b5a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411eaeb6-eb5d-4a93-b8c5-6e72254f26a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6f22e4-b4b9-4704-a9cd-a34d5c459709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a06171e-1aa2-40e9-9720-5a2e45663037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf849fc-67a1-4e93-8c2a-8353010da4a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34387ad1-d79d-4e0f-80a7-302d64abf215",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b800ddfc-0eef-4c69-8312-6c193c061d28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b678a912-7484-4ca0-871b-c76697d73aad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00fc887-2c6b-4ece-b11e-10142dee935f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e1fe4a-2e7b-4462-865d-b2b59fa082a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36063fa1-45b0-4aa1-aa32-a3326bdd2a3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fa01da2-0cac-418c-af40-395e10567d4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-13T19:35:23.913187Z",
     "iopub.status.busy": "2025-09-13T19:35:23.912919Z",
     "iopub.status.idle": "2025-09-13T19:35:25.581154Z",
     "shell.execute_reply": "2025-09-13T19:35:25.580654Z",
     "shell.execute_reply.started": "2025-09-13T19:35:23.913167Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " :: SentenceTransformer initialized | since_start: 4.0 hours, 8.0 minutes, 42.28 seconds | since_last: 4.0 hours, 8.0 minutes, 42.28 seconds :: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' :: SentenceTransformer initialized | since_start: 4.0 hours, 8.0 minutes, 42.28 seconds | since_last: 4.0 hours, 8.0 minutes, 42.28 seconds :: '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentence_transformer_model_name = 'sentence-transformers/all-mpnet-base-v2'\n",
    "sentence_transformer_model_name = 'sentence-transformers/all-distilroberta-v1'\n",
    "\n",
    "st_embed_model = SentenceTransformer(sentence_transformer_model_name)\n",
    "timelogger.log('SentenceTransformer initialized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24b7f749-a8d8-48e4-a725-5a39c8dba4c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-13T19:35:32.530980Z",
     "iopub.status.busy": "2025-09-13T19:35:32.530720Z",
     "iopub.status.idle": "2025-09-13T19:35:32.768732Z",
     "shell.execute_reply": "2025-09-13T19:35:32.768231Z",
     "shell.execute_reply.started": "2025-09-13T19:35:32.530960Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " :: generic methodology phrases encoded START | since_start: 4.0 hours, 8.0 minutes, 49.24 seconds | since_last: 6.95 seconds :: \n",
      " :: generic methodology phrases encoded END | since_start: 4.0 hours, 8.0 minutes, 49.47 seconds | since_last: 0.23 seconds :: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.00535334, -0.00680362,  0.00489835, ...,  0.01841467,\n",
       "        -0.03167962, -0.00509518],\n",
       "       [-0.00022195,  0.00414018,  0.01022067, ..., -0.01404913,\n",
       "        -0.03241679, -0.02545269],\n",
       "       [ 0.01189186,  0.01842937,  0.02846571, ..., -0.03430161,\n",
       "        -0.02436638, -0.03020131],\n",
       "       ...,\n",
       "       [-0.0322062 , -0.01856575,  0.02224941, ..., -0.03424372,\n",
       "        -0.04298654, -0.09180257],\n",
       "       [-0.02929969, -0.07373921, -0.00920677, ...,  0.01079472,\n",
       "         0.03783653, -0.05652968],\n",
       "       [ 0.03346386,  0.0116179 , -0.01428203, ..., -0.07280523,\n",
       "        -0.08783865, -0.02877205]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timelogger.log('generic methodology phrases encoded START')\n",
    "generic_methodology_phrases = [\n",
    "    'research method',\n",
    "    'research methodology',\n",
    "    'methodological approach',\n",
    "    'experimental study',\n",
    "    'empirical evaluation',\n",
    "    'case study',\n",
    "    'simulation study',\n",
    "    'measurement study',\n",
    "    'formal proof'\n",
    "]\n",
    "\n",
    "generic_methodology_phrase_embeddings = st_embed_model.encode(generic_methodology_phrases)\n",
    "timelogger.log('generic methodology phrases encoded END')\n",
    "generic_methodology_phrase_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ae2d78b-ec82-4634-8fc7-9063ba0715a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-13T19:35:36.680470Z",
     "iopub.status.busy": "2025-09-13T19:35:36.680213Z",
     "iopub.status.idle": "2025-09-13T19:35:44.404673Z",
     "shell.execute_reply": "2025-09-13T19:35:44.404177Z",
     "shell.execute_reply.started": "2025-09-13T19:35:36.680451Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " :: text encoded START | since_start: 4.0 hours, 8.0 minutes, 53.39 seconds | since_last: 3.92 seconds :: \n",
      " :: text encoded END | since_start: 4.0 hours, 9.0 minutes, 1.10 seconds | since_last: 7.72 seconds :: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.04587457,  0.02019155,  0.01326159, ..., -0.10766116,\n",
       "         0.05190924,  0.00696904],\n",
       "       [-0.00781274, -0.03953061, -0.00649839, ..., -0.03321218,\n",
       "        -0.0304147 , -0.00362403]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timelogger.log('text encoded START')\n",
    "text_list_embeddings = st_embed_model.encode(texts_only_list)\n",
    "timelogger.log('text encoded END')\n",
    "text_list_embeddings[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6815002-c4b7-4927-a91c-dd24d94a9fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccc4f3c6-164b-43ed-adc9-399adf6de6a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-13T19:35:51.699258Z",
     "iopub.status.busy": "2025-09-13T19:35:51.698997Z",
     "iopub.status.idle": "2025-09-13T19:35:51.704581Z",
     "shell.execute_reply": "2025-09-13T19:35:51.704074Z",
     "shell.execute_reply.started": "2025-09-13T19:35:51.699235Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " :: initiate pos_vectorizer START | since_start: 4.0 hours, 9.0 minutes, 8.40 seconds | since_last: 7.30 seconds :: \n",
      " :: initiate pos_vectorizer END | since_start: 4.0 hours, 9.0 minutes, 8.40 seconds | since_last: 0.00 seconds :: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' :: initiate pos_vectorizer END | since_start: 4.0 hours, 9.0 minutes, 8.40 seconds | since_last: 0.00 seconds :: '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timelogger.log('initiate pos_vectorizer START')\n",
    "pos_pattern = (\n",
    "    # Verb-led methodological action (optional subject/aux/adv, main verb, noun phrase core, optional chained PPs)\n",
    "    # we derive MIMO processing matrices\n",
    "    # we compare the performance\n",
    "    # we factor the MU MIMO precoding matrix\n",
    "    '(<AUX>?<RB>?<V.*><PRT>?<DT>?<J.*>*<N.*>+(<IN><DT>?<J.*>*<N.*>+)*)' #+ '|'\n",
    "    \n",
    "    # Nominal methodological construct (adjective/noun/proper stacks + optional PP tails)\n",
    "    # singular value decomposition\n",
    "    # MIMO processing matrices\n",
    "    # regularized block diagonal AF algorithm\n",
    "    # '(<J.*>*<N.*>+(<N.*>+)*(<IN><J.*>*<N.*>+)*)' # + '|'\n",
    "    \n",
    "    # Metric/result short form\n",
    "    # bit error rate\n",
    "    # BER performance\n",
    "    # SNR gain\n",
    "    # '(<J.*>*<N.*>+)'\n",
    ")\n",
    "pos_vectorizer = KeyphraseCountVectorizer(\n",
    "    spacy_pipeline=nlp,\n",
    "    # pos_pattern=pos_pattern, # '<J.*>*<N.*>+',\n",
    "    # min_df=1, # cutoff\n",
    ")\n",
    "timelogger.log('initiate pos_vectorizer END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ccd1fca-ad48-4e61-b4bf-b845638902d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-13T19:36:10.682586Z",
     "iopub.status.busy": "2025-09-13T19:36:10.682319Z",
     "iopub.status.idle": "2025-09-13T19:36:10.687137Z",
     "shell.execute_reply": "2025-09-13T19:36:10.686582Z",
     "shell.execute_reply.started": "2025-09-13T19:36:10.682567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " :: initiate keybert_model START | since_start: 4.0 hours, 9.0 minutes, 27.39 seconds | since_last: 18.98 seconds :: \n",
      " :: initiate keybert_model END | since_start: 4.0 hours, 9.0 minutes, 27.39 seconds | since_last: 0.00 seconds :: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' :: initiate keybert_model END | since_start: 4.0 hours, 9.0 minutes, 27.39 seconds | since_last: 0.00 seconds :: '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timelogger.log('initiate keybert_model START')\n",
    "keybert_model = KeyBERT(model=st_embed_model)\n",
    "timelogger.log('initiate keybert_model END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f5d612-bafd-419d-9055-8a7bff8d4283",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-13T19:36:35.016974Z",
     "iopub.status.busy": "2025-09-13T19:36:35.016710Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence-transformers/all-distilroberta-v1\n",
      " :: extract 10 keywords START | since_start: 4.0 hours, 9.0 minutes, 51.72 seconds | since_last: 24.34 seconds :: \n"
     ]
    }
   ],
   "source": [
    "print(sentence_transformer_model_name)\n",
    "timelogger.log('extract 10 keywords START')\n",
    "initial_keywords_top10 = keybert_model.extract_keywords(  # TODO: consider using this with candidates=[...] for the next round\n",
    "    docs=texts_only_list[0:100],\n",
    "    top_n=10,\n",
    "    vectorizer=pos_vectorizer,\n",
    "    use_maxsum=True,\n",
    "    nr_candidates=100\n",
    ")\n",
    "initial_keyword_embeddings = st_embed_model.encode([kw[0] for kw in initial_keywords_top10])\n",
    "timelogger.log('extract 10 keywords END')\n",
    "initial_keywords_top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cd5ee2e1-14f8-4b3b-b909-ef3c2ce5c107",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T20:57:46.931323Z",
     "iopub.status.busy": "2025-09-10T20:57:46.930972Z",
     "iopub.status.idle": "2025-09-10T20:57:53.413305Z",
     "shell.execute_reply": "2025-09-10T20:57:53.412381Z",
     "shell.execute_reply.started": "2025-09-10T20:57:46.931296Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " :: extract 100 keywords START | since_start: 1.0 hour, 14.0 minutes, 2.27 seconds | since_last: 0.38 seconds :: \n",
      " :: extract 100 keywords END | since_start: 1.0 hour, 14.0 minutes, 8.74 seconds | since_last: 6.47 seconds :: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('assuming mu mimo channel', 0.5829),\n",
       " ('design mu mimo', 0.5529),\n",
       " ('design mimo', 0.5449),\n",
       " ('find optimum mimo processing matrices', 0.5336),\n",
       " ('perform mimo', 0.5299),\n",
       " ('limitations mimo processing matrices', 0.5292),\n",
       " ('resulting mimo processing matrices', 0.5119),\n",
       " ('jointly optimizes mimo processing matrices bs', 0.5002),\n",
       " ('using mimo channel matrices bs rn', 0.4936),\n",
       " ('consider mu mimo dl system', 0.4799),\n",
       " ('derive mimo processing matrices', 0.4728),\n",
       " ('factor mu mimo', 0.4699),\n",
       " ('rn mimo', 0.4653),\n",
       " ('design mimo processing matrices bs', 0.4631),\n",
       " ('extend mimo', 0.4596),\n",
       " ('estimate effective mimo matrix', 0.4501),\n",
       " ('using mimo channel matrix bs rn', 0.4466),\n",
       " ('function mimo processing matrix', 0.4409),\n",
       " ('multiple antennas', 0.4325),\n",
       " ('derive mimo processing matrices bs', 0.4223),\n",
       " ('derived mimo processing matrices bs', 0.4211),\n",
       " ('assuming mimo', 0.42),\n",
       " ('kth ut mimo', 0.4147),\n",
       " ('fading channels', 0.4047),\n",
       " ('minimize mui kth ut co - channel uts', 0.3998),\n",
       " ('precoding matrix relay', 0.3698),\n",
       " ('describe relaying system', 0.3611),\n",
       " ('combined effective channel matrix rn uts', 0.3568),\n",
       " ('minimizes mu interference', 0.3489),\n",
       " ('regarding total number antennas uts', 0.3468),\n",
       " ('includes mimo processing bs', 0.3352),\n",
       " ('minimize mu interference', 0.3266),\n",
       " ('simultaneously improve channel conditions', 0.3237),\n",
       " ('transmit vector correlation matrix', 0.3149),\n",
       " ('receive antennas kth ut', 0.3054),\n",
       " ('provide information additive noise variances receivers transmitters',\n",
       "  0.2975),\n",
       " ('estimated ul channel dl transmission', 0.2868),\n",
       " ('estimate channel matrix h', 0.2855),\n",
       " ('design spatial processing matrices transmitter', 0.2704),\n",
       " ('describe antenna configuration system', 0.2639),\n",
       " ('obtaining robust communication', 0.2618),\n",
       " ('spatially multiplexed data streams', 0.2417),\n",
       " ('spatially multiplexed data streams kth user', 0.2392),\n",
       " ('denotes transmit vector correlation matrix', 0.239),\n",
       " ('receive matrix uts', 0.2387),\n",
       " ('receive matrices rn', 0.2365),\n",
       " ('transmit power bs', 0.2358),\n",
       " ('supports single communication pair', 0.2358),\n",
       " ('provide reliable transmission', 0.2275),\n",
       " ('channel estimation errors', 0.2257),\n",
       " ('multi - user', 0.2187),\n",
       " ('omit influence additive noise input rn antenna', 0.2056),\n",
       " ('using 4qam modulation', 0.195),\n",
       " ('denotes additive noise correlation matrix', 0.1903),\n",
       " ('design optimum matrix f r c', 0.1825),\n",
       " ('receive matrix', 0.1802),\n",
       " ('assuming large path loss', 0.1774),\n",
       " ('simultaneously using space', 0.1769),\n",
       " ('serving users', 0.1766),\n",
       " ('receive matrix rn', 0.1727),\n",
       " ('feedback noise variance', 0.1697),\n",
       " ('update matrix f', 0.1666),\n",
       " ('stacked vector', 0.1664),\n",
       " ('precoding matrix', 0.1648),\n",
       " ('using following optimization', 0.163),\n",
       " ('define singular value decomposition', 0.1625),\n",
       " ('precoding matrix rn', 0.1621),\n",
       " ('investigate different power allocation algorithms', 0.156),\n",
       " ('reduce distances individual nodes', 0.154),\n",
       " ('precoding matrix f.', 0.1515),\n",
       " ('using matrices f r', 0.149),\n",
       " ('define svd h 2,k', 0.1459),\n",
       " ('mean complex gaussian random variables variance', 0.1448),\n",
       " ('received power kth ut', 0.1395),\n",
       " ('reducing overlap row spaces', 0.1391),\n",
       " ('precoding matrix f', 0.138),\n",
       " ('using quadrature amplitude modulation', 0.1328),\n",
       " ('define svd h 2,k f r', 0.1313),\n",
       " ('optimize kth ut performance', 0.1291),\n",
       " ('proposed system', 0.1265),\n",
       " ('perform resource allocation', 0.126),\n",
       " ('r ∈ r r×r', 0.1241),\n",
       " ('precoding matrix bs', 0.1204),\n",
       " ('denotes identity matrix', 0.1189),\n",
       " ('following equation', 0.1176),\n",
       " ('represents mui', 0.1176),\n",
       " ('proposed algorithm performance system', 0.1119),\n",
       " ('use qr decomposition combination dpc', 0.1119),\n",
       " ('estimates h', 0.1108),\n",
       " ('diagonal positive definite power', 0.1068),\n",
       " ('estimate h 2,k f r k', 0.1053),\n",
       " ('regularized block', 0.1025),\n",
       " ('estimate h', 0.1022),\n",
       " ('compare bit error rate', 0.0998),\n",
       " ('compare performance rbd af algorithm', 0.0979),\n",
       " ('minimize co', 0.0956),\n",
       " ('denotes kth ut', 0.094),\n",
       " ('negligible performance loss', 0.0926),\n",
       " ('denotes number', 0.0885),\n",
       " ('present results simulations', 0.0884)]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timelogger.log('extract 100 keywords START')\n",
    "initial_keywords_top100 = keybert_model.extract_keywords(  # TODO: consider using this with candidates=[...] for the next round\n",
    "    docs=texts_only_list,\n",
    "    top_n=100,\n",
    "    vectorizer=pos_vectorizer\n",
    ")\n",
    "initial_keyword_embeddings = st_embed_model.encode([kw[0] for kw in initial_keywords_top100])\n",
    "timelogger.log('extract 100 keywords END')\n",
    "initial_keywords_top100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "727e8e90-5504-4272-a8f2-02217f9628c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T20:58:04.857955Z",
     "iopub.status.busy": "2025-09-10T20:58:04.857651Z",
     "iopub.status.idle": "2025-09-10T20:58:04.869215Z",
     "shell.execute_reply": "2025-09-10T20:58:04.868444Z",
     "shell.execute_reply.started": "2025-09-10T20:58:04.857933Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['present results simulations',\n",
       " 'estimates h',\n",
       " 'proposed algorithm performance system',\n",
       " 'perform resource allocation',\n",
       " 'proposed system',\n",
       " 'estimate h',\n",
       " 'compare performance rbd af algorithm',\n",
       " 'received power kth ut',\n",
       " 'compare bit error rate',\n",
       " 'describe relaying system',\n",
       " 'estimate h 2,k f r k',\n",
       " 'denotes number',\n",
       " 'investigate different power allocation algorithms',\n",
       " 'using following optimization',\n",
       " 'using matrices f r',\n",
       " 'design mimo',\n",
       " 'provide information additive noise variances receivers transmitters',\n",
       " 'describe antenna configuration system',\n",
       " 'perform mimo',\n",
       " 'design mu mimo',\n",
       " 'optimize kth ut performance',\n",
       " 'denotes kth ut',\n",
       " 'channel estimation errors',\n",
       " 'negligible performance loss',\n",
       " 'provide reliable transmission',\n",
       " 'estimate effective mimo matrix',\n",
       " 'serving users',\n",
       " 'multi - user',\n",
       " 'receive matrices rn',\n",
       " 'consider mu mimo dl system',\n",
       " 'receive matrix rn',\n",
       " 'minimizes mu interference',\n",
       " 'kth ut mimo',\n",
       " 'minimize mu interference',\n",
       " 'denotes additive noise correlation matrix',\n",
       " 'design optimum matrix f r c',\n",
       " 'design mimo processing matrices bs',\n",
       " 'represents mui',\n",
       " 'use qr decomposition combination dpc',\n",
       " 'receive matrix',\n",
       " 'transmit power bs',\n",
       " 'feedback noise variance',\n",
       " 'assuming mimo',\n",
       " 'receive matrix uts',\n",
       " 'obtaining robust communication',\n",
       " 'following equation',\n",
       " 'simultaneously using space',\n",
       " 'factor mu mimo',\n",
       " 'spatially multiplexed data streams kth user',\n",
       " 'precoding matrix rn',\n",
       " 'precoding matrix bs',\n",
       " 'rn mimo',\n",
       " 'includes mimo processing bs',\n",
       " 'using mimo channel matrix bs rn',\n",
       " 'r ∈ r r×r',\n",
       " 'assuming large path loss',\n",
       " 'estimated ul channel dl transmission',\n",
       " 'mean complex gaussian random variables variance',\n",
       " 'using mimo channel matrices bs rn',\n",
       " 'derive mimo processing matrices bs',\n",
       " 'denotes identity matrix',\n",
       " 'combined effective channel matrix rn uts',\n",
       " 'define singular value decomposition',\n",
       " 'define svd h 2,k f r',\n",
       " 'estimate channel matrix h',\n",
       " 'function mimo processing matrix',\n",
       " 'resulting mimo processing matrices',\n",
       " 'supports single communication pair',\n",
       " 'derived mimo processing matrices bs',\n",
       " 'design spatial processing matrices transmitter',\n",
       " 'stacked vector',\n",
       " 'precoding matrix',\n",
       " 'precoding matrix relay',\n",
       " 'spatially multiplexed data streams',\n",
       " 'minimize co',\n",
       " 'minimize mui kth ut co - channel uts',\n",
       " 'diagonal positive definite power',\n",
       " 'regarding total number antennas uts',\n",
       " 'receive antennas kth ut',\n",
       " 'define svd h 2,k',\n",
       " 'precoding matrix f.',\n",
       " 'denotes transmit vector correlation matrix',\n",
       " 'find optimum mimo processing matrices',\n",
       " 'using 4qam modulation',\n",
       " 'limitations mimo processing matrices',\n",
       " 'regularized block',\n",
       " 'assuming mu mimo channel',\n",
       " 'derive mimo processing matrices',\n",
       " 'precoding matrix f',\n",
       " 'update matrix f',\n",
       " 'reducing overlap row spaces',\n",
       " 'using quadrature amplitude modulation',\n",
       " 'jointly optimizes mimo processing matrices bs',\n",
       " 'simultaneously improve channel conditions',\n",
       " 'extend mimo',\n",
       " 'reduce distances individual nodes',\n",
       " 'transmit vector correlation matrix',\n",
       " 'multiple antennas',\n",
       " 'fading channels',\n",
       " 'omit influence additive noise input rn antenna']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "\n",
    "top_n = 10\n",
    "pairwise_distances = euclidean_distances(initial_keyword_embeddings, generic_methodology_phrase_embeddings)\n",
    "closest_distances_per_keyword = [[index, min(ds)] for index, ds in enumerate(pairwise_distances)]\n",
    "sorted_closest_distances_per_keyword = sorted(closest_distances_per_keyword, key=lambda x: x[1])\n",
    "keywords = [initial_keywords_top100[index][0] for (index, distance) in sorted_closest_distances_per_keyword]\n",
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "08ee2604-a831-44ef-a74a-01dc46c43d8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T20:06:25.133187Z",
     "iopub.status.busy": "2025-09-10T20:06:25.132749Z",
     "iopub.status.idle": "2025-09-10T20:06:25.139951Z",
     "shell.execute_reply": "2025-09-10T20:06:25.138961Z",
     "shell.execute_reply.started": "2025-09-10T20:06:25.133147Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1.4426476], [1, 1.4687278]]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest_distances_per_keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5d349f34-0ac0-4899-849b-e15940bd8f04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T19:59:54.248592Z",
     "iopub.status.busy": "2025-09-10T19:59:54.247977Z",
     "iopub.status.idle": "2025-09-10T19:59:54.254548Z",
     "shell.execute_reply": "2025-09-10T19:59:54.253531Z",
     "shell.execute_reply.started": "2025-09-10T19:59:54.248561Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4426476, 1.4526964],\n",
       "       [1.4687278, 1.4915861]], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65862d2-feff-4b50-945e-2e4c87eb013e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_311_2",
   "language": "python",
   "name": "python_311_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
